{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd3033e",
   "metadata": {},
   "source": [
    "# Image Analysis 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187637d6",
   "metadata": {},
   "source": [
    "This Jupyter notebook is part of the course Image Analysis from Radboud University (Nijmegen, Netherlands), and it was developed by researchers of Radboud University Medical Center (Nijmegen, Netherlands).\n",
    "\n",
    "You should have obtained this notebook by downloading it from the official Brightspace page of the course.\n",
    "If this is not the case, you should contact the course coordinator at this email address: geert.litjens@radboudumc.nl\n",
    "\n",
    "This notebook formulates an assignment as part of the course, and the content of this notebook should be used solely to develop a solution to this assignment.\n",
    "You should not make the code provided in this notebook, or your own solution, publicly available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc7b2e",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` by substituting `None` variables or by adding your own solution and any place that says \"YOUR ANSWER HERE\" with your answers to the questions. Note that it is perfectly fine to substitute the images in the exercises with your own if you want to. Please fill in your name and collaborators below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7367f1",
   "metadata": {},
   "source": [
    "## Students\n",
    "Please fill in this cell with your name and e-mail address. This information will be used to track completion of the assignments.\n",
    "\n",
    "* Name student #1, email address: ...\n",
    "* Name student #2, email address (optional): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f766c1",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "* Groups: You should work in **groups of maximum 2 people**.\n",
    "* Deadline for this assignment: \n",
    " * Preferably before May 12th\n",
    " * Please upload your **fully executed** notebook to BrightSpace\n",
    "  The file name of the notebook you submit must be ```NameSurname1_NameSurname2.ipynb```\n",
    "\n",
    "This notebooks contains cells with snippets of code that we provide in order to load and visualize data, but also some convenience functions that could be useful to develop your assignment.\n",
    "\n",
    "We also provide templates for functions that have to be implemented, with a given list of input variables and some output variables.\n",
    "\n",
    "Your submission should contain the **fully executed** notebook with **your code** implemented, as well as **your answers** to questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8dfdf7",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f2a5e",
   "metadata": {},
   "source": [
    "First, we import the basic libraries necessary to develop this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33183941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski # For reading images\n",
    "import skimage.transform as skit # Basic image transformation functions\n",
    "import skimage.filters # Functions for image filtering\n",
    "from   scipy.signal import convolve2d # 2D convolution function\n",
    "from   scipy.ndimage import gaussian_filter # Filter images with a Gaussian function or derivative\n",
    "from   skimage.color import label2rgb # Color labels for segmented objects\n",
    "from   skimage.transform import hough_circle, hough_circle_peaks\n",
    "from   skimage.draw import circle_perimeter # Draw a circle on an image\n",
    "import matplotlib.pyplot as plt # Plotting and visalization of images\n",
    "import numpy as np # Basic math and array functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8805e30-3152-463f-979b-ea0e45341f55",
   "metadata": {},
   "source": [
    "# Basic convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1387a00-881d-4868-bbc8-e59b81d32652",
   "metadata": {},
   "source": [
    "First we will covert the basics of the convolution operation. Below is a function to plot an image in addition to its pixel values, which makes what a convolution is doing a bit more insightful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801f9b9-30b9-4b73-8378-efc50b87f5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imshow_with_values(array, axis):\n",
    "    axis.axis(False)\n",
    "    axis.imshow(array, cmap='gray');\n",
    "    for (j,i),label in np.ndenumerate(array):\n",
    "        axis.text(i, j, label,ha='center',va='center', fontsize=12, color=\"black\", backgroundcolor=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f80862-3072-4f9f-8ac0-1b0492328a92",
   "metadata": {},
   "source": [
    "The cell below generates a simple 5x5 image and a 3x3 filter and convolves them. You can modify the filter to see what happens with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cf225-c2ba-4e0d-b5b1-8f0cba5454b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8)) \n",
    "test_img = np.arange(1, 26).reshape(5, 5)\n",
    "test_filter = np.array(([1,1,1], [1,1,1], [1,1,1]), dtype=\"ubyte\")\n",
    "convolved_test_img = convolve2d(test_img, test_filter, mode='same', boundary='fill')\n",
    "imshow_with_values(test_img, axes[0]);\n",
    "imshow_with_values(test_filter, axes[1]);\n",
    "imshow_with_values(convolved_test_img, axes[2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26c44ea-d2fa-4b60-94d7-ea05ad28afc7",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** Experiment a bit with different ways convolution can handle the boundaries of the image. What happens when you change `mode` in the `convolve2d` from `same` to `valid`? Or when you change `boundary` from `fill` to `wrap`? Can you explain why these differences happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37a2c6-7ca1-4f28-b698-1129407c47f2",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c6ec5-b9b0-4669-9d53-31870ddaef98",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** As you may notice, the values in the image increase substantially after convolution. Why is that? What can you do to mitigate this value increase such that mean of the convolved area stays the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5280173-582f-441e-88ab-4768fb5d9c8a",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f50cb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Noise removal\n",
    "In this part of the exercise we will look at image filtering for enhancement of image quality. We'll start with a clean color images and we will add two different types of noise to it. The first type is Gaussian noise, which is normally distributed, the second one is salt-and-pepper noise, which switches a pixel on or off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5c2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rocket = ski.data.rocket()\n",
    "rocket_gaussian_noise = np.clip(rocket + 16 * np.random.default_rng().normal(0, 1, rocket.shape), 0, 255).astype(\"ubyte\")\n",
    "rocket_1D = rocket.flatten()\n",
    "salt_indices = np.random.choice(rocket_1D.shape[0], 25000, replace=False)\n",
    "pepper_indices = np.random.choice(rocket_1D.shape[0], 25000, replace=False)\n",
    "rocket_1D[salt_indices] = 255\n",
    "rocket_1D[pepper_indices] = 0\n",
    "rocket_salt_pepper_noise = rocket_1D.reshape(rocket.shape)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8)) \n",
    "axes[0].imshow(rocket); # Show the orignal image\n",
    "axes[1].imshow(rocket_gaussian_noise); # Show the image with Gaussian noise\n",
    "axes[2].imshow(rocket_salt_pepper_noise); # Show the image with salt-and-pepper noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d73432",
   "metadata": {
    "tags": []
   },
   "source": [
    "As a first step we will try to remove the noise with smoothing filters, such as averaging filters. First we define a convolution filter for RGB images which applies a filter to each channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb00790-444a-468a-b4f8-ce6f87b87528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve2d_rgb(image, filter, **kwargs):\n",
    "    return np.array([convolve2d(image[:, :, i], filter, **kwargs) for i in range(3)]).transpose(1,2,0).astype(\"ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283296d-7237-4b2d-8fc4-70659a5acc71",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Assignment:** Now we need to define the smoothing filter. We will start with a basic 5x5 averaging filter, replace the `None` below. Then we visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23945915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace None with your code\n",
    "average_filter = None\n",
    "filtered_rocket_gaussian_noise = convolve2d_rgb(rocket_gaussian_noise, average_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4c6c4-82f5-4dae-92e7-7f318f1b0d24",
   "metadata": {},
   "source": [
    "Let's show the result of the filtering process below. You can experiment with different filter sizes if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1dc04-855f-4b33-8f37-5fd47f5ea99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8)) \n",
    "axes[0].imshow(rocket); # Show the orignal image\n",
    "axes[1].imshow(rocket_gaussian_noise); # Show the noisy image\n",
    "axes[2].imshow(filtered_rocket_gaussian_noise); # Show the filtered image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f55cc8-0f2d-42cf-8572-50b447cafa18",
   "metadata": {},
   "source": [
    "Let's also have a look at one row through the image in a bit more detail to get a feeling how the noise affects the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef94cc-285b-4c90-8715-2d79b5ab0916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "axes[0].plot(rocket[250,:,0])\n",
    "axes[1].plot(rocket_gaussian_noise[250,:,0])\n",
    "axes[2].plot(filtered_rocket_gaussian_noise[250,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5160d6-4095-4f01-b820-a94db469a8ec",
   "metadata": {},
   "source": [
    "Let's try to fix the image with the salt-and-pepper noise using the same filter and visualize those results as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d96ecd-b68a-4cb5-83ba-a877b8576b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rocket_salt_pepper_noise = convolve2d_rgb(rocket_salt_pepper_noise, average_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f98b2b1-e1ec-4271-9fec-69fc85149dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8)) \n",
    "axes[0].imshow(rocket); # Show the orignal image\n",
    "axes[1].imshow(rocket_salt_pepper_noise); # Show the noisy image\n",
    "axes[2].imshow(filtered_rocket_salt_pepper_noise); # Show the smoothed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745eb51-d037-4ef0-b89b-2d754bd059c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "axes[0].plot(rocket[250,:,0])\n",
    "axes[1].plot(rocket_salt_pepper_noise[250,:,0])\n",
    "axes[2].plot(filtered_rocket_salt_pepper_noise[250,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8829e9c-6499-434c-8cdf-738e35d282f8",
   "metadata": {},
   "source": [
    "As you can see from the result image and the line plot, much noise is still present in the image, especially in the background. We can probably do a better job using a median filter. Below is the skeleton of a median filter function for RGB images. Modify it to apply a median filter to every channel separately. You can use the `convolve2d_rgb` function as an example. To apply a median filter to a single channel, have a look at the `ski.filters.median` function. Remember you can use `?ski.filters.median` to get the documentation. **Note:** the median filter can also use non-square filter shapes, you can use a square filter for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af803b-791f-453a-99fd-e85d564e3444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter_rgb(image, filter_size, **kwargs):\n",
    "    filtered_image = None\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e61ef-9850-4db3-8521-af2b248d0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_filtered_rocket = median_filter_rgb(rocket_salt_pepper_noise, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9bd0c-12b6-453e-9a69-6bdbe40be6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8)) \n",
    "axes[0].imshow(rocket); # Show the orignal image\n",
    "axes[1].imshow(rocket_salt_pepper_noise); # Show the noisy image\n",
    "axes[2].imshow(median_filtered_rocket); # Show the smoothed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaaf5a4-1fa4-45fe-afac-c7ec1e5e0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "axes[0].plot(rocket[250,:,0])\n",
    "axes[1].plot(rocket_salt_pepper_noise[250,:,0])\n",
    "axes[2].plot(median_filtered_rocket[250,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1646c956",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font color=\"blue\">**Question:** Now try to use the median filter for the image corrupted with Gaussian noise. What do you observe? Is it as effective as a averaging filter? What happens if you increase the value of the center pixel of the averaging filter? (Don't forget to alter the normalization constant). Just provide your observations and reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788d733-648e-40d3-b4a2-494be43e3423",
   "metadata": {
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a146192",
   "metadata": {},
   "source": [
    "# Edge Detection\n",
    "Filtering using convolutions can also be used to highlight specific elements in an image, for example edges. Typically you can use a difference operator to highlight the edges. However, this can cause issues in the presence of noise. Let's have a look at some basic edge operators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848aea17",
   "metadata": {},
   "source": [
    "### Difference, Prewitt and Sobel operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42044dcf",
   "metadata": {},
   "source": [
    "First, let's define the different filters. You can flip the filters to a different axis (x or y) by using the `transpose` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_x = np.array([[1, 0, -1]])\n",
    "difference_y = difference_x.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbefc4c-a9b5-4405-b89a-d9e07f0f0d7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now let's see what happens when we apply this to a normal and a noisy image. For ease of visualization we will use grayscale images for the edge detection part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b16b09-ec20-40ea-95fa-e66177f44901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rocket_gray = np.mean(rocket, axis=2)\n",
    "rocket_noise_gray = np.clip(rocket_gray + 8 * np.random.default_rng().normal(0, 1, rocket_gray.shape), 0, 255).astype(\"ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893df886-2243-44f7-b375-0e0d41e0eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal image\n",
    "rocket_dx = convolve2d(rocket_gray, difference_x, mode='same')\n",
    "rocket_dy = convolve2d(rocket_gray, difference_y, mode='same')\n",
    "rocket_grad_mag = np.sqrt(rocket_dx**2 + rocket_dy**2)\n",
    "\n",
    "# Noisy image\n",
    "rocket_noise_dx = convolve2d(rocket_noise_gray, difference_x, mode='same')\n",
    "rocket_noise_dy = convolve2d(rocket_noise_gray, difference_y, mode='same')\n",
    "rocket_noise_grad_mag = np.sqrt(rocket_noise_dx**2 + rocket_noise_dy**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a27a26-2fdc-4d00-a8c6-858d52b11c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8)) \n",
    "axes[0].imshow(rocket_grad_mag, cmap = \"gray\"); # Show the orignal image\n",
    "axes[1].imshow(rocket_noise_grad_mag, cmap = \"gray\"); # Show the noisy image\n",
    "axes[2].imshow(rocket_noise_grad_mag[50:150, 400:500], cmap = \"gray\")\n",
    "print(\"Noise to background ratio: \" + str(np.std(rocket_noise_grad_mag[50:100, 400:450]) / np.std(rocket_grad_mag[50:100, 400:450])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8922f-29e4-41f0-b4c0-6ffdf6b375eb",
   "metadata": {},
   "source": [
    "As you can see the regular difference operator for edge detection cannot handle noise very well, it creates a lot of 'wrong' edge pixels in the gradient magnitude image. As you have seen during the lecture, there are other filters which incorporate smoothing, such as the Prewitt or Sobel edge detection filters. Let's have a look at how they do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abc62f-f2c6-4a32-af75-60289a159bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prewitt_x = convolve2d(np.array([[1, 1, 1]]).transpose(), difference_x, mode=\"full\")\n",
    "prewitt_y = convolve2d([[1, 1, 1]], difference_y, mode=\"full\")\n",
    "print(prewitt_x)\n",
    "print(prewitt_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa623f-730e-40a1-8234-65b21519ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal image\n",
    "rocket_dx = convolve2d(rocket_gray, prewitt_x, mode='same')\n",
    "rocket_dy = convolve2d(rocket_gray, prewitt_y, mode='same')\n",
    "rocket_grad_mag = np.sqrt(rocket_dx**2 + rocket_dy**2)\n",
    "\n",
    "# Noisy image\n",
    "rocket_noise_dx = convolve2d(rocket_noise_gray, prewitt_x, mode='same')\n",
    "rocket_noise_dy = convolve2d(rocket_noise_gray, prewitt_y, mode='same')\n",
    "rocket_noise_grad_mag = np.sqrt(rocket_noise_dx**2 + rocket_noise_dy**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed93c47d-b99a-4ff8-a6c7-881e77efb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8)) \n",
    "axes[0].imshow(rocket_grad_mag, cmap = \"gray\"); # Show the orignal image\n",
    "axes[1].imshow(rocket_noise_grad_mag, cmap = \"gray\"); # Show the noisy image\n",
    "axes[2].imshow(rocket_noise_grad_mag[50:150, 400:500], cmap = \"gray\")\n",
    "print(\"Noise to background ratio: \" + str(np.std(rocket_noise_grad_mag[50:100, 400:450]) / np.std(rocket_grad_mag[50:100, 400:450])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498c873-479f-4400-a35e-9f8834ec4e79",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font color=\"blue\">**Question:** Can you explain what difference you see between the noisy image convolved with the difference kernel and with the Prewitt kernel? And what causes this difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551bc9f3-5eeb-4e73-9d33-bb305f961689",
   "metadata": {
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f43ee-23db-4e3b-a256-0e08a6dc0d09",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Assignment:** Modify the function generating `prewitt_x` and `prewitt_y` to generate Sobel kernels instead. Conduct the edge detection using the Sobel filters. What is the difference between thet two?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830011f-b2b0-43b0-8c38-874b5c6ca11c",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e46b8-c62d-4345-96d7-dfca622507a6",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a93cf-0859-4328-9181-b46d0df591b8",
   "metadata": {},
   "source": [
    "For the next exercise, we will implement the Canny Edge detection algorithm from scratch. It contains these four steps:\n",
    "1. Smooth the image to remove noise\n",
    "2. Calculate the gradient, gradient magnitude and angle\n",
    "3. Non-local maxima suppression to thin edges\n",
    "4. Hysteris thresholding\n",
    "\n",
    "The first step is intended to get rid of noise in the image. The second step calculates the gradient magnitude and angle to identify the strength of the edges and the direction. The third step thins the edges so only the strongest edge pixels per edge remains. The last steps removes weak edges which are not attached to a strong edge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a560902-fbf8-4669-a4fe-4552a469067f",
   "metadata": {},
   "source": [
    "We start by generating the filters we will use for the smoothing and edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb8bd3-f8bf-4aec-8b70-9f7309e8e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_filter = (1/25) * np.ones((5, 5))\n",
    "prewitt_x = convolve2d(np.array([[1, 1, 1]]).transpose(), difference_x, mode=\"full\")\n",
    "prewitt_y = convolve2d([[1, 1, 1]], difference_y, mode=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3a4d0-444c-48b3-8565-b94cd41afa89",
   "metadata": {},
   "source": [
    "The function below performs the non-maxima suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278396cc-30c6-43bf-a1e2-f1a65cf91efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def non_max_suppression(gradient_magnitude, gradient_angle):\n",
    " \n",
    "    image_row, image_col = gradient_magnitude.shape\n",
    " \n",
    "    output = np.zeros(gradient_magnitude.shape)\n",
    "    \n",
    "    # Loop over all pixels in the image\n",
    "    for row in range(1, image_row - 1):\n",
    "        for col in range(1, image_col - 1):\n",
    "            # Get the local edge angle in radians\n",
    "            angle = gradient_angle[row, col]\n",
    "\n",
    "            # Check whether it is a vertical or a horizontal angle. The angles range from -pi to pi.\n",
    "            # Extract the pixels before and after the current one based on the direction of the edge\n",
    "            if ((-np.pi / 4) <= angle <= (np.pi / 4)) or ((3 * np.pi / 4) <= angle) or ((-3 * np.pi / 4) >=  angle):\n",
    "                before_pixel = gradient_magnitude[row, col - 1]\n",
    "                after_pixel = gradient_magnitude[row, col + 1]\n",
    "            else:\n",
    "                before_pixel = gradient_magnitude[row + 1, col]\n",
    "                after_pixel = gradient_magnitude[row - 1, col]\n",
    "\n",
    "            # If the current pixel is higher than its neigbors, keep it, otherwise becomes 0\n",
    "            if gradient_magnitude[row, col] >= before_pixel and gradient_magnitude[row, col] >= after_pixel:\n",
    "                output[row, col] = gradient_magnitude[row, col]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da24f8-e016-42ba-8bd8-442ccc732f92",
   "metadata": {},
   "source": [
    "Now we will conduct the steps in turn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989c3a0-91d2-4b47-a74b-8398a9fb4e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Smooth the image to remove noise\n",
    "smoothed_rocket = convolve2d(rocket_noise_gray, average_filter, mode=\"same\")\n",
    "# 2. Get the derivatives in both directions and calculate the magnitude and angle maps\n",
    "rocket_dx = convolve2d(smoothed_rocket, prewitt_x, mode=\"same\")\n",
    "rocket_dy = convolve2d(smoothed_rocket, prewitt_y, mode=\"same\")\n",
    "rocket_grad_mag = np.sqrt(rocket_dx**2 + rocket_dy**2)\n",
    "rocket_grad_ang = np.arctan2(rocket_dy, rocket_dx)\n",
    "# 3. Perform the thinning of the edges\n",
    "rocket_thinned = non_max_suppression(rocket_grad_mag, rocket_grad_ang)\n",
    "# 4. Remove weak edges not connceted to strong edges\n",
    "rocket_edge = ski.filters.apply_hysteresis_threshold(rocket_thinned, np.percentile(rocket_thinned, 80), np.percentile(rocket_thinned, 97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0849138b-9693-48b7-99bd-300b6b550e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(32, 12)) \n",
    "axes[0][0].imshow(label2rgb(rocket_edge, rocket_noise_gray, colors=[(0,1,0)], alpha=0.5, bg_label=0, bg_color=None, kind=\"overlay\")) # Original grayscale image with edges overlayed in green\n",
    "axes[0][1].imshow(smoothed_rocket, cmap = \"gray\"); # Smoothed image\n",
    "axes[0][2].imshow(rocket_grad_mag, cmap = \"gray\"); # Gradient magnitude\n",
    "axes[1][0].imshow(rocket_grad_ang, cmap = \"gray\"); # Gradient angle\n",
    "axes[1][1].imshow(rocket_thinned, cmap = \"gray\"); # Thinned edges\n",
    "axes[1][2].imshow(rocket_edge, cmap = \"gray\"); # Final result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee4d37-eb4c-4978-9844-c817fc0de373",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Assignment:** Below is the same process as above, but now we are going to use Gaussian derivatives to perform the smoothing and edge detection in one step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab958b0d-1d32-40f6-89b1-81ee12e5604d",
   "metadata": {},
   "source": [
    "First, here is a cell to visualize the Gaussian function and its derivatives for various scales (sigma). This is simply to allow you to explore how these change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16dd428-3e89-4a4e-9782-e6d125653c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 3.\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y = np.linspace(-10, 10, 100)\n",
    "\n",
    "x, y = np.meshgrid(x, y)\n",
    "gauss = (1/(2*np.pi*sigma**2) * np.exp(-(x**2/(2*sigma**2) + y**2/(2*sigma**2))))\n",
    "gauss_dx = (x * np.exp(-((x**2+y**2)/(2*sigma**2)))) / (2*np.pi*sigma**4)\n",
    "gauss_dy = (y * np.exp(-((x**2+y**2)/(2*sigma**2)))) / (2*np.pi*sigma**4)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8), subplot_kw={'projection':'3d'}) \n",
    "axes[0].plot_surface(x, y, gauss, rstride=3, cstride=3, linewidth=1, antialiased=True,\n",
    "                cmap=\"viridis\");\n",
    "axes[0].contourf(x, y, gauss, zdir='z', offset=-0.02, cmap=\"viridis\")\n",
    "axes[0].set_zlim(-0.02,0.005)\n",
    "axes[0].set_zticks(np.linspace(0,0.015,2))\n",
    "axes[0].view_init(30, 45)\n",
    "axes[1].plot_surface(x, y, gauss_dx, rstride=3, cstride=3, linewidth=1, antialiased=True,\n",
    "                cmap=\"viridis\");\n",
    "axes[1].contourf(x, y, gauss_dx, zdir='z', offset=-0.01, cmap=\"viridis\")\n",
    "axes[1].set_zlim(-0.01,0.005)\n",
    "axes[1].set_zticks(np.linspace(0,0.005,2))\n",
    "axes[1].view_init(30, 45)\n",
    "axes[2].plot_surface(x, y, gauss_dy, rstride=3, cstride=3, linewidth=1, antialiased=True,\n",
    "                cmap=\"viridis\");\n",
    "axes[2].contourf(x, y, gauss_dy, zdir='z', offset=-0.01, cmap=\"viridis\")\n",
    "axes[2].set_zlim(-0.01,0.005)\n",
    "axes[2].set_zticks(np.linspace(0,0.005,2))\n",
    "axes[2].view_init(30, 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13303681-b63e-42af-a1f2-2b037fe0c625",
   "metadata": {},
   "source": [
    "The function below you have to modify to create the gradient magnitude using convolutions with filters based on Gaussian derivatives, which can perform smoothing and edge detection simultanously. You have to use the function `gaussian_filter` on `rocket_noise_gray_float`, which filter the image based on a specified `sigma` and the order of the derivative. An order of 0 means the Gaussian function itself, `[1, 0]` means the first-order partial derivative in the x-direction and `[0, 1]` in the y-direction. Remember to use `?gaussian_filter` if you need more explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8b060-b168-4629-84a6-33c508b6a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with your code\n",
    "rocket_noise_gray_float = rocket_noise_gray.astype(float)\n",
    "rocket_dx = None\n",
    "rocket_dy = None\n",
    "rocket_grad_mag = None\n",
    "rocket_grad_ang = None\n",
    "rocket_thinned = non_max_suppression(rocket_grad_mag, rocket_grad_ang)\n",
    "rocket_edge = ski.filters.apply_hysteresis_threshold(rocket_thinned, np.percentile(rocket_thinned, 5), np.percentile(rocket_thinned, 95))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b7ad8-a019-4ade-aed7-14ae872d88d1",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Assignment:** The function below will again plot the end-result and the thinned_edges. Explore with different values of `sigma`. What happens when you increase or decrease the value of `sigma`? *Note:* you might need to alter the threshold values in `apply_hysteresis_threshold` above when you alter `sigma`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c0178-1a35-47de-94e9-2ec5d50221ed",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086efe8-e6de-4a43-8cdc-abbfa78c89fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8)) \n",
    "axes[0].imshow(label2rgb(rocket_edge, rocket_noise_gray, colors=[(0,1,0)], alpha=0.5, bg_label=0, bg_color=None, kind=\"overlay\"))\n",
    "axes[1].imshow(rocket_thinned, cmap = \"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002ee5f",
   "metadata": {},
   "source": [
    "# Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe8ebc",
   "metadata": {},
   "source": [
    "After the edge detection, it makes sense to actually extract the relevant objects from the image. If these objects can be parameterized using a mathematical equation, such as lines or circles, a Hough Transform might be a good choice. In this exercise we will use the Hough Transform for Circles to extract coins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3140015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = ski.data.coins()\n",
    "plt.imshow(coins, cmap=\"gray\"); # Show the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aecf9c2",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Assignment:** First, we will extract the boundaries of the coins using the Canny algorithm you developed above. Replace the None below with your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64034a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with your code\n",
    "coin_edges = None\n",
    "plt.imshow(coin_edges);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef16a52a",
   "metadata": {},
   "source": [
    "This should generate pretty decent result, there are some artifacts, but those should not affect the results of our Hough Transform too much. The function below performs a Hough Transform on the image for a predetermined set of radii. It is currently setup to find a single small coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d006285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect two radii\n",
    "hough_radii = np.arange(15, 25, 5)\n",
    "hough_res = hough_circle(coin_edges, hough_radii)\n",
    "\n",
    "# Select the most prominent 3 circles\n",
    "accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii, min_xdistance=5, min_ydistance=5, total_num_peaks=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc8fa07-6627-4666-8f92-3d0839d4f6c6",
   "metadata": {},
   "source": [
    "The cell below visualizes the detection, the extracted coin and a slice (it is a 3D volume) of the Hough Transform of `coins_edges`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab3d1c-eae4-4af9-97a9-5f5fb65acd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(24, 8))\n",
    "coins_rgb = np.stack((coins,)*3, axis=-1)\n",
    "for center_y, center_x, radius in zip(cy, cx, radii):\n",
    "    circy, circx = circle_perimeter(center_y, center_x, radius,\n",
    "                                    shape=coins.shape)\n",
    "    coins_rgb[circy, circx] = (220, 20, 20)\n",
    "\n",
    "ax[0].imshow(coins_rgb, cmap=\"gray\");\n",
    "ax[1].imshow(coins[cy[0]-radii[0]:cy[0]+radii[0], cx[0]-radii[0]:cx[0]+radii[0]], cmap=\"gray\");\n",
    "ax[2].imshow(hough_res[0], cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad94e5",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Assignment:** Modify the function above to extract all coins at once. You need to alter the parameters of both the `hough_circle` function and the `hough_circle_peak` function. Can you explain what you see in the Hough Transform image? What does the `hough_circle_peak` function do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30f240-0f9f-4e33-9c6e-ee0b596f9f59",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "fdba351d0eac33baae35e799220eeb9212faffb54ecf3b81a18522e517be605d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
