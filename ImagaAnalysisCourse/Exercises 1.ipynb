{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd3033e",
   "metadata": {},
   "source": [
    "# Image Analysis 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187637d6",
   "metadata": {},
   "source": [
    "This Jupyter notebook is part of the course Image Analysis from Radboud University (Nijmegen, Netherlands), and it was developed by researchers of Radboud University Medical Center (Nijmegen, Netherlands).\n",
    "\n",
    "You should have obtained this notebook by downloading it from the official Brightspace page of the course.\n",
    "If this is not the case, you should contact the course coordinator at this email address: geert.litjens@radboudumc.nl\n",
    "\n",
    "This notebook formulates an assignment as part of the course, and the content of this notebook should be used solely to develop a solution to this assignment.\n",
    "You should not make the code provided in this notebook, or your own solution, publicly available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc7b2e",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` by substituting `None` variables or by adding your own solution and any place that says \"YOUR ANSWER HERE\" with your answers to the questions. Note that it is perfectly fine to substitute the images in the exercises with your own if you want to. Please fill in your name and collaborators below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7367f1",
   "metadata": {},
   "source": [
    "## Students\n",
    "Please fill in this cell with your name and e-mail address. This information will be used to track completion of the assignments.\n",
    "\n",
    "* Name student #1, email address: ...\n",
    "* Name student #2, email address (optional): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f766c1",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "* Groups: You should work in **groups of maximum 2 people**.\n",
    "* Deadline for this assignment: \n",
    " * Preferably before April 28th\n",
    " * Send your **fully executed** notebook to: geert.litjens@radboudumc.nl\n",
    "* The file name of the notebook you submit must be ```NameSurname1_NameSurname2.ipynb```\n",
    "\n",
    "This notebooks contains cells with snippets of code that we provide in order to load and visualize data, but also some convenience functions that could be useful to develop your assignment.\n",
    "\n",
    "We also provide templates for functions that have to be implemented, with a given list of input variables and some output variables.\n",
    "\n",
    "Your submission should contain the **fully executed** notebook with **your code** implemented, as well as **your answers** to questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8dfdf7",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f2a5e",
   "metadata": {},
   "source": [
    "First, we import the basic libraries necessary to develop this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33183941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski # For reading images\n",
    "import skimage.transform as skit # Basic image transformation functions\n",
    "import matplotlib.pyplot as plt # Plotting and visalization of images\n",
    "import numpy as np # Basic math and array functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f50cb8",
   "metadata": {},
   "source": [
    "# Colors and grayscale\n",
    "First let's get visualize an image and get some information from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5c2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "astronaut = ski.data.astronaut() # Get astronaut image as Numpy array\n",
    "plt.imshow(astronaut); # Show the image\n",
    "print(\"Image shape: \" + str(astronaut.shape)) # Print the shape (i.e. dimenions) of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d73432",
   "metadata": {},
   "source": [
    "As a first exercise, let's visualize the color channels individually. You can use Numpy indexing, specifically, you can use the colon symbol to use the full extent of a dimensions: `array[:,0]` will take all columns and the first row. To visualize a channel, use the cell below the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "astronaut_red = None\n",
    "astronaut_green = None\n",
    "astronaut_blue = None\n",
    "# SUBSTITUTE None ABOVE OR PLACE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea508944",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4)) # This creates a plot with 3 horizontal subplots\n",
    "axes[0].imshow(astronaut_red, cmap=\"gray\"); # Fill the first axes with the red channel\n",
    "axes[1].imshow(astronaut_green, cmap=\"gray\"); # Fill the first axes with the green channel\n",
    "axes[2].imshow(astronaut_blue, cmap=\"gray\"); # Fill the first axes with the blue channel\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590ae65",
   "metadata": {},
   "source": [
    "Now let's turn the image into a proper grayscale image by averaging the three color channels. You can either use simple math operators (e.g. + and /) or use the `np.mean` function. If you need explanation of a function, you can always type ?<function_name> in a cell, so `?np.mean` will explain the arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb_image):\n",
    "    # SUBSTITUTE None ABOVE OR PLACE YOUR CODE HERE\n",
    "    return gray_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be7f79",
   "metadata": {},
   "source": [
    "This cell below will show you the results of your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb54dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "gray_astronaut = rgb2gray(astronaut)\n",
    "\n",
    "ax[0].imshow(astronaut)\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(gray_astronaut, cmap=plt.cm.gray)\n",
    "ax[1].set_title(\"Grayscale (Mean)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a146192",
   "metadata": {},
   "source": [
    "# Sampling and quantization\n",
    "Now let's move to sampling and interpolation. As mentioned during the lecture, when interacting with images, especially in acquiring them, sampling and quanitzation are important components. They determine the quality of the digital signal (image on our case), but also the computing power you need to handle the data. First, we will inspect what happens when we sample poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0de39",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5f33f0",
   "metadata": {},
   "source": [
    "First, we will generate a test pattern based on the sum of a sine and cosine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pattern = np.zeros((512,512), dtype=\"ubyte\")\n",
    "for y in range(512):\n",
    "    for x in range(512):\n",
    "        test_pattern[y,x] = np.sin(y/8) + np.cos(x/8)\n",
    "plt.imshow(test_pattern);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d415300",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** What is the frequency of the pattern?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec1e8b",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa490a",
   "metadata": {},
   "source": [
    "Now let's explore when we sample this 'function'. Note that the sampling here will be imperfect because we are not sampling a real signal, but already a sampled version of this signal (we turned the continous sine function into an image). So you will get more artifacts than in sampling a real signal, but you should still clearly see a typical effect of sampling at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c49821c",
   "metadata": {},
   "source": [
    "The cells below you can use to 'sample' and 'reconstruct' the image. The first rescale will sample only every `sub_factor` pixel. The second rescale will reconstruct the image to its original state. The cell below that visualizes the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a19638",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_factor = 4\n",
    "sampled_pattern = skit.rescale(test_pattern, 1/sub_factor)\n",
    "restored_pattern = skit.rescale(sampled_pattern, sub_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb88b2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "ax[0].imshow(test_pattern)\n",
    "ax[0].set_title(\"Pattern\")\n",
    "ax[1].imshow(sampled_pattern)\n",
    "ax[1].set_title(\"Sampled\")\n",
    "ax[2].imshow(restored_pattern)\n",
    "ax[2].set_title(\"Reconstructed\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056179f",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** At what sampling frequency do you see the first problems with the reconstruction? What typical change do you see in the pattern?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1fb7b4",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e0427",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd0995",
   "metadata": {},
   "source": [
    "Now we'll have a look at quantization. Remember that quantization is important, for example, to efficiently store data. If you need fewer bits you need to store the data, you also need much less computer memory, network bandwith and processing time to go through the data. First, let's load an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820c55f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "camera = ski.data.camera()\n",
    "plt.imshow(camera, cmap = \"gray\");\n",
    "print(\"Lowest pixel value in the image: \" + str(camera.min()))\n",
    "print(\"Lowest pixel value in the image: \" + str(camera.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67815ff4",
   "metadata": {},
   "source": [
    "First, let's implement a simple quantization function and look at the results. You should only need to use multiplication or division and rounding to achieve;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_image(image, nr_of_values):\n",
    "    quantized_image = None\n",
    "    # SUBSTITUTE None ABOVE OR PLACE YOUR CODE HERE    \n",
    "    return quantized_image.astype(\"ubyte\") # Make sure the image is stored as integer for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_values = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695f8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "quantized_camera = quantize_image(camera, nr_of_values)\n",
    "\n",
    "ax[0].imshow(camera, cmap=plt.cm.gray)\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(quantized_camera, cmap=plt.cm.gray)\n",
    "ax[1].set_title(\"Quantized (\" + str(nr_of_values) + \" values)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b24288",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** Experiment a bit with the quantization. You should be able to reduce the number of values quite a bit! However, this is a relatively 'dumb' way to quantize an image. Can you explain why? Maybe have a look at the values in the image a bit more closely. Can you come up with another approach that could reduce the number of values even more without degrading the visual quality? If you want you can implement it, but describing it in some words is fine. *Note:* Consider the function `np.unique`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d299cff1",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002ee5f",
   "metadata": {},
   "source": [
    "# Intensity transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ecd88e",
   "metadata": {},
   "source": [
    "The last topic of the first exercise is intensity transformations. This is useful in many domain, for example in medical imaging where the interesting aspects of an acquired image are in very specific intensity ranges. But also in natural images, such as photographs it can be relevant, for example if the photograph is too dark or too bright."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0c136",
   "metadata": {},
   "source": [
    "### Basic transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4eb140",
   "metadata": {},
   "source": [
    "First, we will look at some basic transformation that do not require any parameters or templates. Let's load an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3140015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "moon = ski.data.moon()\n",
    "plt.imshow(moon, cmap=\"gray\"); # Show the image\n",
    "print(\"Image shape: \" + str(moon.shape)) # Print the shape (i.e. dimenions) of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac866a",
   "metadata": {},
   "source": [
    "We will implement two basic transforms: the log transform and the inversion transform. You can have a look at the slides (or Google it) if you forgot what they are supposed to do. Implement them yourself below. Remember that intensity transform are done on a per-pixel basis; you do not need any information from the neighbors. *Note:* If you see `division by 0` errors, remember what happens when you do `log(0)`. How can you fix that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logarithmic transformation\n",
    "def log_transform(gray_image):\n",
    "    \"\"\"Apply a logarithmic transformation\n",
    "    \"\"\"\n",
    "    log_image = None\n",
    "    # SUBSTITUTE None ABOVE OR PLACE YOUR CODE HERE    \n",
    "    return log_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert transformation\n",
    "def invert(gray_image):\n",
    "    \"\"\"Apply an inversion transformation\n",
    "    \"\"\"\n",
    "    inverted_image = None\n",
    "    # SUBSTITUTE None ABOVE OR PLACE YOUR CODE HERE        \n",
    "    return inverted_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6dc9a",
   "metadata": {},
   "source": [
    "Below is a cell which will visualize you results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "moon_log = log_transform(moon)\n",
    "moon_invert = invert(moon)\n",
    "moon_log_invert = log_transform(moon_invert)\n",
    "\n",
    "ax[0][0].imshow(moon, cmap=plt.cm.gray)\n",
    "ax[0][0].set_title(\"Original\")\n",
    "ax[0][1].imshow(moon_log, cmap=plt.cm.gray)\n",
    "ax[0][1].set_title(\"Log Transformed\")\n",
    "ax[1][0].imshow(moon_invert, cmap=plt.cm.gray)\n",
    "ax[1][0].set_title(\"Inverted\")\n",
    "ax[1][1].imshow(moon_log_invert, cmap=plt.cm.gray)\n",
    "ax[1][1].set_title(\"Inverted and Log Transformed\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97a1b9",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** Describe in your own words what the transforms do in the context of the visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ac79c",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7b757",
   "metadata": {},
   "source": [
    "### Contrast stretching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d79af",
   "metadata": {},
   "source": [
    "The first transforms we implemented where useful, but rather simple. More importantly, they do not allow you to change them based on the content of the image. Now let's look at contrast stretching, which we can adapt to different images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ec5dd",
   "metadata": {},
   "source": [
    "In order to apply the contrast stretching operation, let's first define a general contrast stretching function. The inputs should be at least (1) the input image, (2) the window range values ```p0``` and ```pk```, as defined in the lecture.\n",
    "**Note**: The end results should not contain intensity values larger than ```qk``` or lower than ```q0```. Consider the `np.clip` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f72f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast stretching\n",
    "def contrast_stretching(x, p0, pk, q0=0., qk=255.):\n",
    "    \"\"\"Apply contrast stretching\n",
    "    \"\"\"\n",
    "    stretched = None\n",
    "    rescaled = None\n",
    "    return rescaled\n",
    "    # SUBSTITUTE None ABOVE OR PLACE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define here p0 and pk, picking proper values and call the\n",
    "# contrast stretching function passing the correct parameter(s)\n",
    "p0 = 0\n",
    "pk = 255\n",
    "moon_cs = None\n",
    "# SUBSTITUTE None ABOVE OR PLACE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63465c9",
   "metadata": {},
   "source": [
    "The cell below will again visualize your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00acaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "ax[0].imshow(moon, cmap=plt.cm.gray)\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(moon_cs, cmap=plt.cm.gray)\n",
    "ax[1].set_title(\"Contrast Strecthced\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91e93e",
   "metadata": {},
   "source": [
    "# Histogram matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66413b13",
   "metadata": {},
   "source": [
    "The last, and most involved exercise, will implement Histogram Matching. This is an ideal method if you have any image whose color and visual properties you like and want other images to mimic. The first image will then be used as a template for the others. To start, let's load our template image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764becb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ski.data.cat()\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "ax[0].imshow(astronaut)\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(cat)\n",
    "ax[1].set_title(\"Template\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa9ab25",
   "metadata": {},
   "source": [
    "So here we will match the colors of the astronaut to be similar to the picture of the cat. This will require us to take several steps (see the slides if you need a refresher):\n",
    "\n",
    "1. Obtain the histograms of both images for every color channel (R, G, B)\n",
    "2. Calculate the normalized cumulative histogram\n",
    "3. Define the lookup table to perform the transformation for every color channel \n",
    "4. Transform the all color channels of the image\n",
    "\n",
    "The first two steps you will implement yourself using the `np.histogram` and `np.cumsum` functions. You can operate under the assumption that all images have values ranging from 0 - 255 (inclusive). Read the documentation for the parameters carefully, it is easy to make a mistake! Remember how to index a color channel from the first exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1101c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histograms for all channels\n",
    "astronaut_hst_red = None\n",
    "astronaut_hst_green = None\n",
    "astronaut_hst_blue = None\n",
    "cat_hst_red = None\n",
    "cat_hst_green = None\n",
    "cat_hst_blue = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96197b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "astronaut_cumhist_red = None\n",
    "astronaut_cumhist_normalized_red = astronaut_cumhist_red / astronaut_cumhist_red[-1] \n",
    "astronaut_cumhist_green = None\n",
    "astronaut_cumhist_normalized_green = astronaut_cumhist_green / astronaut_cumhist_green[-1] \n",
    "astronaut_cumhist_blue = None\n",
    "astronaut_cumhist_normalized_blue = astronaut_cumhist_blue / astronaut_cumhist_blue[-1] \n",
    "cat_cumhist_red = None\n",
    "cat_cumhist_normalized_red = cat_cumhist_red / cat_cumhist_red[-1] \n",
    "cat_cumhist_green = None\n",
    "cat_cumhist_normalized_green = cat_cumhist_green / cat_cumhist_green[-1] \n",
    "cat_cumhist_blue = None\n",
    "cat_cumhist_normalized_blue = cat_cumhist_blue / cat_cumhist_blue[-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5b189",
   "metadata": {},
   "source": [
    "The function below will plot the cumulative, normalized histograms for both the astronaut and cat images. This is a quick check whether you implemented the function correctly: they should be different and end at 1.0. *Note:* the `[:-1]` is a correction for the fact the np.histogram will output the bin edges, which has one more entry than the bin heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb780490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "ax[0].bar(astronaut_hst_red[1][:-1], astronaut_cumhist_normalized_red, width=1);\n",
    "ax[0].set_title(\"Astronaut\")\n",
    "ax[1].bar(cat_hst_red[1][:-1], cat_cumhist_normalized_red, width=1);\n",
    "ax[1].set_title(\"Cat\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d53c2",
   "metadata": {},
   "source": [
    "The cells below will create the lookup table to perform the conversion for each color channel. It does this by interpolating between the cumulative histograms (see the slides for a visual example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b15c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LUT(source_normcumhist, target_normcumhist):\n",
    "    LUT = np.interp(source_normcumhist, target_normcumhist, range(256))\n",
    "    return LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc23f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUT_red = create_LUT(astronaut_cumhist_normalized_red, cat_cumhist_normalized_red)\n",
    "LUT_green = create_LUT(astronaut_cumhist_normalized_green, cat_cumhist_normalized_green)\n",
    "LUT_blue = create_LUT(astronaut_cumhist_normalized_blue, cat_cumhist_normalized_blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99952d83",
   "metadata": {},
   "source": [
    "Now you need to apply the lookup tables to the channels from the astronaut image. You can do that by simply treating the LUTs as a function: `LUT_red[<red color channel of the astronaut image>]`. The result will be a color channel matched to the cat image. Then replace the color channels in the `astronaut_matched` image with the transformed ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6eaded",
   "metadata": {},
   "outputs": [],
   "source": [
    "astronaut_matched = astronaut.copy()\n",
    "astronaut_matched[None] = None\n",
    "astronaut_matched[None] = None\n",
    "astronaut_matched[None] = None\n",
    "# SUBSTITUTE None ABOVE OR PLACE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b1ff5",
   "metadata": {},
   "source": [
    "The cell below again should give you the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6dcf75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "ax[0].imshow(astronaut)\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(cat)\n",
    "ax[1].set_title(\"Template\")\n",
    "ax[2].imshow(astronaut_matched)\n",
    "ax[2].set_title(\"Original (Histogram Matched)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99ecfd",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Assignment:** Check whether your implementation is correct. You can do that by calculating the cumulative histogram of the transformed image and the template image (i.e. the cat) and plotting them. They should, after transformation, be the same shape (except for some potential clipping at the beginning). If not, your implementation is note entirely correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bebf0d7",
   "metadata": {},
   "source": [
    "YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
