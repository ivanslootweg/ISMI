{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd3033e",
   "metadata": {},
   "source": [
    "# Image Analysis 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187637d6",
   "metadata": {},
   "source": [
    "This Jupyter notebook is part of the course Image Analysis from Radboud University (Nijmegen, Netherlands), and it was developed by researchers of Radboud University Medical Center (Nijmegen, Netherlands).\n",
    "\n",
    "You should have obtained this notebook by downloading it from the official Brightspace page of the course.\n",
    "If this is not the case, you should contact the course coordinator at this email address: geert.litjens@radboudumc.nl\n",
    "\n",
    "This notebook formulates an assignment as part of the course, and the content of this notebook should be used solely to develop a solution to this assignment.\n",
    "You should not make the code provided in this notebook, or your own solution, publicly available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc7b2e",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` by substituting `None` variables or by adding your own solution and any place that says \"YOUR ANSWER HERE\" with your answers to the questions. Note that it is perfectly fine to substitute the images in the exercises with your own if you want to. Please fill in your name and collaborators below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7367f1",
   "metadata": {},
   "source": [
    "## Students\n",
    "Please fill in this cell with your name and e-mail address. This information will be used to track completion of the assignments.\n",
    "\n",
    "* Name student #1, email address: ...\n",
    "* Name student #2, email address (optional): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f766c1",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "* Groups: You should work in **groups of maximum 2 people**.\n",
    "* Deadline for this assignment: \n",
    " * Preferably before May 12th\n",
    " * Please upload your **fully executed** notebook to BrightSpace\n",
    "  The file name of the notebook you submit must be ```NameSurname1_NameSurname2.ipynb```\n",
    "\n",
    "This notebooks contains cells with snippets of code that we provide in order to load and visualize data, but also some convenience functions that could be useful to develop your assignment.\n",
    "\n",
    "We also provide templates for functions that have to be implemented, with a given list of input variables and some output variables.\n",
    "\n",
    "Your submission should contain the **fully executed** notebook with **your code** implemented, as well as **your answers** to questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8dfdf7",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f2a5e",
   "metadata": {},
   "source": [
    "First, we import the basic libraries necessary to develop this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33183941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski # For reading images\n",
    "import skimage.segmentation # For the segmentation exercise\n",
    "from skimage.segmentation._slic import _enforce_label_connectivity_cython # Efficient label connectivity checking\n",
    "\n",
    "from sklearn import datasets as skldatasets # Example datasets for machine learning\n",
    "from sklearn import neighbors # KNN classifier\n",
    "from sklearn.calibration import CalibratedClassifierCV # Needed to get probabilities from SVM classifiers\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import pairwise_distances_argmin # For the color quantization section\n",
    "from sklearn.model_selection import train_test_split #\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import expit\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt # Plotting and visalization of images\n",
    "import numpy as np # Basic math and array functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8805e30-3152-463f-979b-ea0e45341f55",
   "metadata": {},
   "source": [
    "# K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1387a00-881d-4868-bbc8-e59b81d32652",
   "metadata": {},
   "source": [
    "Although K-means clustering typically is used to identify clusters in an unsupervised fashion, it also has some surprising use-cases. First, we will revisit our quantization exercise from Week 1. To make it a bit more challenging, we will look at color image quantization this time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf14f13-981e-4405-aa66-631bb42c6a12",
   "metadata": {},
   "source": [
    "## Color Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b9eb6-91d0-4a50-84fb-c8414aea1468",
   "metadata": {},
   "source": [
    "Let's again start by loading a nice image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801f9b9-30b9-4b73-8378-efc50b87f5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Summer Palace photo\n",
    "china = skldatasets.load_sample_image(\"china.jpg\")\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 8)) \n",
    "axes.imshow(china); # Show the orignal image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1381f-8c60-4b35-bbd3-48b649ed1854",
   "metadata": {},
   "source": [
    "Below is a very simple quantization function which simply limits every channel (R, G, and B) to a predetermined number of values linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde8b79-bd9c-488f-b824-8e0a6111d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_image(image, nr_of_values):\n",
    "    values_per_channel = np.ceil(np.cbrt(nr_of_values)).astype(\"ubyte\")\n",
    "    quantized_image = np.array([np.round(values_per_channel * (image[:, :, i].astype(\"float\") / 255.)) * (255 // values_per_channel) for i in range(3)]).transpose(1,2,0)\n",
    "    return quantized_image.astype(\"ubyte\") # Make sure the image is stored as integer for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f80862-3072-4f9f-8ac0-1b0492328a92",
   "metadata": {},
   "source": [
    "A standard RGB image can have 255*255*255 different colors, so more than 16 million. Let's try to reduce that to 27, so 3 values per color channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd5d7e-ad62-4ec3-acc6-b31c015467dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_values = 27\n",
    "quant_china = quantize_image(china, nr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cf225-c2ba-4e0d-b5b1-8f0cba5454b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "axes[0].imshow(china)\n",
    "axes[1].imshow(quant_china);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e4b6e6-02f7-4770-bc08-03a12ea881a1",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Assignment:** Now let's try to select these 27 colors in a way that is a bit smarter. The idea is that we can use the K-means algorithm to find the largest clusters of color values and use those cluster centers as the best values for quantization. The below cell should perform this task. Modify it by using the `KMeans` class so that the function completes. Remember that you can get the manual by using `?KMeans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907f454-078e-4dbb-99ad-65f54db815b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to reshape the image to a list of pixels instead of a 2D image\n",
    "w, h, d = original_shape = china.shape\n",
    "image_array = np.reshape(china, (w * h, d))\n",
    "\n",
    "# We perform the clustering on a subset of pixels to make it complete a bit faster. You can also identify the clusters using all the pixels to be a bit more accurate\n",
    "image_array_sample = shuffle(image_array, random_state=0)[:10000]\n",
    "\n",
    "# Your code here, replace the None's below\n",
    "kmeans = None\n",
    "kmeans.fit(image_array_sample)\n",
    "labels = kmeans.predict(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f839efb-381a-423e-8c9d-d06d03bfbdaa",
   "metadata": {},
   "source": [
    "Given the predicted labels, the function below recreates the image with just the 27 color values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc46b6f-959a-438e-b322-cbae8f7027c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_image(cluster_centers, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the cluster centers & labels\"\"\"\n",
    "    image = np.zeros((w, h, 3))\n",
    "    label_idx = 0\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            image[i][j] = cluster_centers[labels[label_idx]]\n",
    "            label_idx += 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4255e8aa-3cc7-49fa-8470-f1de82ed5fc9",
   "metadata": {},
   "source": [
    "Now we recreate te actual image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f6a5c-fa8f-45ca-9354-8ba4f830ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_china_kmeans = recreate_image(kmeans.cluster_centers_, labels, w, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e55bc3-7069-4246-b3b8-72e330d0f648",
   "metadata": {},
   "source": [
    "Plot the figures to allow for a visual comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603a19f-1882-4d7a-a1be-811843844f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(36, 16)) \n",
    "axes[0][0].imshow(china)\n",
    "axes[0][1].imshow(quant_china_kmeans.astype(\"ubyte\"))\n",
    "axes[0][2].imshow(quant_china)\n",
    "axes[1][0].imshow(china[200:300, 150:250])\n",
    "axes[1][1].imshow(quant_china_kmeans[200:300, 150:250].astype(\"ubyte\"));\n",
    "axes[1][2].imshow(quant_china[200:300, 150:250]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26c44ea-d2fa-4b60-94d7-ea05ad28afc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font color=\"blue\">**Question:** Experiment a bit with different number of values. How many values do you need to make the image visually (almost) the same as the original? Could you come up with a way to quantify the difference between the original and the quantified versions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37a2c6-7ca1-4f28-b698-1129407c47f2",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a513df-14da-4a8c-a41c-aa909580f5a3",
   "metadata": {},
   "source": [
    "## Superpixel Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b12ce6-305f-4060-b2d8-1289d077eafe",
   "metadata": {},
   "source": [
    "Another atypical application area of KMeans is to perform so-called superpixel segmentation of an image. This identifies visually similar, spacially close regions and labels them. In downstream tasks, features could be extracted from these regions to perform classification and thus segmentation. To give us a bit more freedom on how to conduct this segmentation, you can find a simple, relatively inefficient implementation of KMeans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32481c7-c27f-44a8-85e0-30ca3871795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(features, centroids, nr_iterations=10, metric=\"euclidean\"):\n",
    "    for i in range(nr_iterations): # Perform a number of iterations, each time updating the cluster centers\n",
    "        clusters = []\n",
    "        for feature_vector in features: # Calculate the distance between every pixel and every cluster center\n",
    "            dist = np.sqrt(np.sum(np.square(centroids - feature_vector), axis=-1))\n",
    "            clusters.append(np.argmin(dist)) # Store the cluster label for each pixel\n",
    "        for c in range(len(centroids)):\n",
    "            centroids[c] = np.mean(features[np.where(np.array(clusters) == c)], axis=0)\n",
    "        # Check whether any cluster assignments changed since last iteration. If not, stop!\n",
    "        if i == 0:\n",
    "            old_clusters = np.array(clusters).copy()\n",
    "        else:\n",
    "            if (old_clusters == np.array(clusters)).all():\n",
    "                break\n",
    "            else:\n",
    "                old_clusters = np.array(clusters).copy()\n",
    "    return clusters, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e118e2a-6314-46f3-bb38-b1a757a5af8d",
   "metadata": {},
   "source": [
    "The SLIC algorithm is implemented below. It converts an image to a list of feature vector, one entry for each pixel. The features consist of spatial positions (x, y) and color values (r, g, b), so five in total. Subsequently, the cluster centroids for K-means are initialized on a grid across the image. By subsequently applying K-means to the feature list, every pixels will be assigned to a cluster center, which thanks to the positional features will be spatially close, and similar in color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681a0f8-c9ea-45bf-88d7-4d902f418693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLIC(image, nr_superpixels=100, nr_iterations=10, metric=\"euclidean\"):\n",
    "    image_float = image / 255. # To make the positions and the colors have roughly the same value range (0 - 1), divide by 255\n",
    "     # Generate the position features\n",
    "    row_pos = np.arange(0, 1., 1./image.shape[0])\n",
    "    col_pos = np.arange(0, 1., 1./image.shape[1])\n",
    "    xx, yy = np.meshgrid(col_pos, row_pos)\n",
    "    indices = np.array([yy,xx]).transpose(1,2,0)\n",
    "    \n",
    "    # Combine the positions features and the color features\n",
    "    feat_matrix = np.concatenate([indices, image_float], axis=2).reshape(-1, 5)\n",
    "    \n",
    "    # Now initialize the centroids. First determine how many clusters there should be per row and column\n",
    "    superpixels_per_row = np.ceil(np.sqrt(nr_superpixels) * (image.shape[1] / image.shape[0]))\n",
    "    superpixels_per_col = np.ceil(nr_superpixels / superpixels_per_row)\n",
    "    step_size_x = image.shape[1] / superpixels_per_row\n",
    "    step_size_y = image.shape[0] / superpixels_per_col\n",
    "    centroid_row_pos = np.arange(step_size_x / 2, image.shape[1], step_size_x).astype(\"int\")\n",
    "    centroid_col_pos = np.arange(step_size_y / 2, image.shape[0], step_size_y).astype(\"int\")\n",
    "    centroids_xx, centroids_yy = np.meshgrid(centroid_row_pos, centroid_col_pos)\n",
    "    centroid_rgb_vals = image_float[centroids_yy, centroids_xx]\n",
    "    centroid_indices = np.array([centroids_yy/image_float.shape[0],centroids_xx/image_float.shape[1]]).transpose(1,2,0)\n",
    "    centroid_feat_matrix = np.concatenate([centroid_indices, centroid_rgb_vals], axis=2).reshape(-1,5)\n",
    "    \n",
    "    # Perform the K-means given the pixel feature matrix and the centroids\n",
    "    clusters, centroid_feat_matrix = KMeans(feat_matrix, centroid_feat_matrix, nr_iterations, metric)\n",
    "    \n",
    "    # Removes the small cluster and ensure connectivity \n",
    "    segment_size = (image.shape[0] * image.shape[1]) // nr_superpixels\n",
    "    result = _enforce_label_connectivity_cython(np.array(clusters).reshape(image.shape[0], -1).astype(np.intp)[None], int(0.5 * segment_size), 3 * segment_size)\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56af38-1769-439f-a02d-d027ea5b0dee",
   "metadata": {},
   "source": [
    "Perform the SLIC algorithm on a subimage to reduce the waiting time for the algorithm to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cd47e-2bce-405a-b0e4-c3ef8af7fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "china_sub = china[0:200,0:200]\n",
    "china_slic = SLIC(china_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559eba7-e69f-4110-bf9d-c2b57704e02e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8)) \n",
    "axes[0].imshow(china_sub)\n",
    "axes[1].imshow(skimage.segmentation.mark_boundaries(china_sub, china_slic));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d866fb-3ab1-49c4-8a70-6b90a111d16a",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Assignment:** There are two things in the K-means function for SLIC specifically that are not implemented yet. The first is that the spatial position features and color features cannot be weighted, i.e. they all contribute equally to the distance. However, there are 3 color features and 2 spatial features, thus color features play to big a role. Adept the function to allow for separate weighting of the spatial and color features and investigate how this changes the results. What happens to the superpixels when you make the weighting for the position features higher? The second limitation is that currently only the Euclidean distance is implemented. This limits our flexibility. Implement at least one other distance metric (e.g. City Block Distance). You can use the metric parameter to allow for selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96427ce7-3be1-4f62-b2da-da19db527a4a",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d73432",
   "metadata": {
    "tags": []
   },
   "source": [
    "## kNN classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd8126-5d90-4899-8870-8726476040c0",
   "metadata": {},
   "source": [
    "The last assignment of this section will focus on supervised nearest neighbors algorithms, specifically k-Nearest Neighbor Classification. kNN determines a label for new points by determining which neighbors are closed. The amount of neighbors has to be specified, the afformentioned `k`. Let's inspect the effect of the value of `k` on the decision boundary of the kNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42d8dd-4859-4d8a-b888-cab143876d88",
   "metadata": {},
   "source": [
    "The function below we will use throughout the rest of the exercises to plot the decision boundaries in conjuction with the data for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63c4db-287a-4421-a349-286eae666e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y, clfs, X_test=None, y_test=None):\n",
    "    if not isinstance(clfs, list):\n",
    "        clfs = [clfs]\n",
    "    # preprocess dataset, split into training and test part\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.02\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    if max(y) == 1:\n",
    "        cm = plt.cm.RdYlBu        \n",
    "        cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    else:\n",
    "        cm = plt.cm.RdYlBu\n",
    "        cm_bright = ListedColormap(['#FF0000', '#FFFF00', '#0000FF'])\n",
    "    plt.figure(figsize=(8 * len(clfs), 8))\n",
    "    ax = plt.subplot(1, len(clfs)+1, 1)\n",
    "    ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright,\n",
    "               edgecolors='k')\n",
    "    if X_test is not None and y_test is not None:\n",
    "        # Plot the testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "                   edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "    for i, clf in enumerate(clfs):        \n",
    "        ax = plt.subplot(1, len(clfs)+1, i+2)\n",
    "        ax.set_title(clf.__str__().split(\"(\")[0])        \n",
    "        if X_test is not None and y_test is not None:\n",
    "            score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        if y.max() > 1:\n",
    "            Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "            # Put the result ianto a color plot\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "        else:\n",
    "            if hasattr(clf, \"predict_proba\"):\n",
    "                Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "            elif hasattr(clf, \"decision_function\"):\n",
    "                Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "            else:\n",
    "                Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "            # Put the result into a color plot\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            ax.contourf(xx, yy, Z, cmap=cm, alpha=.8, levels=[-1.0,  -0.25, 0, 0.25, 0.5, 0.75, 1.0, 1.25, 2.0])\n",
    "            CS = ax.contour(xx, yy, Z, colors = \"black\", levels=[-1.0, -0.25, 0, 0.25, 0.5, 0.75, 1.0, 1.25, 2.0])\n",
    "            ax.clabel(CS, CS.levels, inline=True, fontsize=10)\n",
    "        # Plot the training points\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "        # Plot the testing points\n",
    "        if X_test is not None and y_test is not None:\n",
    "            ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                       edgecolors='k', alpha=0.6)    \n",
    "            \n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if X_test is not None and y_test is not None:\n",
    "            ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                    size=15, horizontalalignment='right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57101528-d15b-4664-810f-4eaa2c3d18bb",
   "metadata": {},
   "source": [
    "The cell below loads some example data and then trains two kNN classifier, one with `k=1` and one with `k=40`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe18bd1-3a64-40a3-bf73-19d90edc7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "iris = skldatasets.load_iris()\n",
    "\n",
    "# we only take the first two features. We could avoid this ugly\n",
    "# slicing by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "knn_1 = neighbors.KNeighborsClassifier(1)\n",
    "knn_1.fit(X, y)\n",
    "\n",
    "knn_40 = neighbors.KNeighborsClassifier(40)\n",
    "knn_40.fit(X, y)\n",
    "\n",
    "plot_decision_boundary(X, y, [knn_1, knn_40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28820f28-0173-4867-bdcc-e99f856f4edd",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** Describe the difference you see in the decision boundaries. What would you expect the effect to be on generalization? How could you test that? If you have a good idea, you could try to adapt the cell above and test which `k` is better for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b49c3a-1469-4d91-9cdc-80bfa338e872",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916d6da-ced1-4462-985d-1706514e533a",
   "metadata": {},
   "source": [
    "# Linear classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c83b47-eeb2-4075-8c74-800fac669764",
   "metadata": {},
   "source": [
    "Now let's change gears and look at parametric classifiers. We will first investigate the differences between three different linear classifier: standard linear regression, logistic regression and linear support vector classifiers (SVC). First, let's implement a simple one variable linear regression, which can be solved analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0523e9a-3fbd-405f-a332-883c27b212ab",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Assignment:** Fix the class below by replacing the `None` statements in the `fit` function. You can either have a look at the lecture slides or inspect this page on Wikipedia: https://www.wikiwand.com/en/Simple_linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdee8e3-e93b-4e57-a8dc-31876c435d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # YOUR CODE HERE # \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.coef_ * X + self.intercept_,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e1a05-42a2-4f77-93e1-38a717821978",
   "metadata": {},
   "source": [
    "Once you have managed to implement the linear regression, let's do a comparison in a one variable case to logistic regression. The dell below generates a simple random dataset with two classes to experiment with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2216d0-e8f0-40e0-ac26-c3f9fb813cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = skldatasets.make_blobs(n_samples=40, n_features=1, centers=2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111634a2-1dd5-4504-9164-1ad851785507",
   "metadata": {},
   "source": [
    "In the cell below, we will fit our model and a logistic regression model to the data. We will then plot the fitted models for X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449734c9-1ac0-4531-aaf3-0655c2cfb37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = SimpleLinearRegression()\n",
    "ols.fit(X, y)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(sorted(X[:, 0]), ols.coef_ * sorted(X[:, 0]) + ols.intercept_, linewidth=1)\n",
    "plt.axhline(.5, color='.5')\n",
    "\n",
    "# Fit the classifier\n",
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# and plot the result\n",
    "plt.scatter(X.ravel(), y, color='black', zorder=20)\n",
    "\n",
    "loss = expit(sorted(X[:, 0]) * clf.coef_ + clf.intercept_).ravel()\n",
    "plt.plot(sorted(X[:, 0]), loss, color='red', linewidth=3)\n",
    "\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')\n",
    "plt.xticks(np.arange(X.min(), X.max()))\n",
    "plt.yticks([0, 0.5, 1])\n",
    "plt.ylim(-.25, 1.25)\n",
    "plt.legend(('Logistic Regression Model', 'Linear Regression Model'),\n",
    "           loc=\"lower right\", fontsize='small')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c04d0-156b-4f7e-92e4-c72c728336db",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** Based on the loss function plotted above, describe the disadvantage of using a regular regression model for classification. What are the advantages of logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad103a-17ac-4bcc-bf8b-3f5438146666",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2de267-3f7e-42ed-8160-b0765c4db16f",
   "metadata": {},
   "source": [
    "Now we will make it slightly more complex and look at two features and also include linear SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a066816-c407-4f66-b41b-f5d3c413f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = skldatasets.make_blobs(n_samples=40, n_features=2, centers=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b60aa-a9da-4e95-a0fc-0a08a88613b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logr = linear_model.LogisticRegression().fit(X,y)\n",
    "clf_linr = linear_model.LinearRegression().fit(X, y)\n",
    "clf_linsvm = CalibratedClassifierCV(LinearSVC(C=100, loss=\"hinge\", random_state=42, max_iter=10000)).fit(X, y)\n",
    "plot_decision_boundary(X,y,[clf_linr, clf_logr, clf_linsvm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59368b4b-ab8d-4791-8397-9b7d4b394f62",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** Describe the differences you see in the classifier boundaries. What happens when you change the C parameter of the linear SVM? Can you predict what its use is? Which classifier would you typically use as first choice and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01dd040-8365-4343-b579-54faf5b3f34b",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6759a1-f71a-4408-b8d6-fb3c20d59f9e",
   "metadata": {},
   "source": [
    "# Decision trees and random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4748ce-6bf0-4b00-9f39-2ca94462ae64",
   "metadata": {},
   "source": [
    "The last exercise of this week will focus around decision trees and ensembles of decision trees (also called Random Forests). Decision trees have some very attractive advantages: they are simple to implement, they are explainable and can be quite accurate. However, they are also notorious for overfitting (i.e. getting perfect results on the training data but performing poorly on new data). Let's explore how they behave in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19917d70-d0ce-4b54-b336-8ed3a93c7c42",
   "metadata": {},
   "source": [
    "The cell below loads a toy dataset and first an unconstrained decision tree. We subsequently plot the decision boundary and a graph representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046c648-8bac-4f46-86a6-1d5a84b4464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris = skldatasets.load_iris()\n",
    "\n",
    "# Pick the first two features\n",
    "X, y = shuffle(iris.data[:, :2], iris.target, random_state=0)\n",
    "X_train = X[:100,:2]\n",
    "X_test = X[100:,:2]\n",
    "y_train = y[:100]\n",
    "y_test = y[100:]\n",
    "\n",
    "# Train\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "plot_decision_boundary(X, y, clf)\n",
    "\n",
    "plt.figure(figsize=(24,24))\n",
    "plot_tree(clf, filled=True, feature_names=iris.feature_names, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16a862-92e9-4e30-bf7f-30016d3960fa",
   "metadata": {},
   "source": [
    "As you can see an unconstrained decision tree become quite complex, let's have a look at how it performs on unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25031bd7-0156-421a-8b4d-d908bb200a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on the training data: \" + str(np.sum(clf.predict(X_train) == y_train)/len(y_train)))\n",
    "print(\"Accuracy on the test data: \" + str(np.sum(clf.predict(X_test) == y_test)/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0cf46-fc42-48e6-b363-2b281c11920a",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** As you can see, there is quite a big gap in accuracy. Let's try to constrain the tree and make this gap smaller. You have to modify `DecisionTreeClassifier()` by providing additional parameters. An example of the one you could test is max_depth, but there are also others. Try to get the best possible test accuracy and visualize the tree and decision boundary. What happens? Can you explain what the parameters you tried did? What was the highest test accuracy you could achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10c9ea-ea8f-4fb4-8e98-02cf4548e9b3",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8b4b65-097f-4a35-8acf-037735aab422",
   "metadata": {},
   "source": [
    "The last exercise will compare all the classifier we have encountered up till now in addition to the Random Forest, an ensemble of decision trees. We will inspect their performance on diverse datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34f9ee-3bab-43e0-a76d-660631b8c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set of classifiers we will explore\n",
    "classifiers = [\n",
    "    neighbors.KNeighborsClassifier(n_neighbors=3),\n",
    "    CalibratedClassifierCV(LinearSVC()),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)]\n",
    "\n",
    "X, y = skldatasets.make_classification(n_samples=500, n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [skldatasets.make_moons(n_samples=500, noise=0.3, random_state=0),\n",
    "            skldatasets.make_circles(n_samples=500, noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    trained_classifiers = []\n",
    "    for clf in classifiers:\n",
    "        clf.fit(X_train, y_train)\n",
    "        trained_classifiers.append(clf)\n",
    "        \n",
    "    plot_decision_boundary(X_train, y_train, trained_classifiers, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb425ddb-1373-4a4a-a69a-1f44e28b1e6c",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:** By looking at the different datasets and the results of the classifiers (accuracy in the bottom right of each graph), you should be able to identify some weaknesses for specific classifiers. What classifier performance the best overal? Where does each classifier excel? You can experiment a bit with the dataset functions to see if you can discover anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005551d-bdd9-438e-b7df-d8cbbb29885c",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
