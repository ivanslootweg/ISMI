{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivanslootweg/ISMI/blob/main/assignment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8_FJ1tZ4xLH"
      },
      "source": [
        "# Intelligent Systems in Medical Imaging 2023\n",
        "\n",
        "This Jupyter notebook is part of the course Intelligent Systems in Medical Imaging (ISMI) from Radboud University (Nijmegen, Netherlands), and it was developed by researchers of Radboud University Medical Center (Nijmegen, Netherlands).\n",
        "\n",
        "You should have obtained this notebook by downloading it from the official Brightspace page of the course.\n",
        "\n",
        "This notebook formulates an assignment as part of the ISMI course, and the content of this notebook should be used solely to develop a solution to this assignment. You should not make the code provided in this notebook, or your own solution, publicly available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkmzu6q94xLJ"
      },
      "source": [
        "## Teaching Assistants\n",
        "\n",
        "* Bram de Wilde (bram.dewilde@radboudumc.nl)\n",
        "* Pierpaolo Vendittelli (pierpaolo.vendittelli@radboudumc.nl)\n",
        "* Joeran Bosma (joeran.bosma@radboudumc.nl)\n",
        "* Stephan Dooper (stephan.dooper@radboudumc.nl)\n",
        "\n",
        "For questions about the assignments that go beyond the content, you can contact Bram de Wilde. Questions about the content are addressed in the tutorial sessions. You are also encouraged to use the Brightspace discussion forums to discuss content of the assignments. We will also keep an eye out there to help!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoNBiAsT4xLK"
      },
      "source": [
        "## Guidelines and instructions\n",
        "Make sure you write code in any place that says \"YOUR CODE HERE\" by substituting `None` variables or by adding your own solution. Make sure you write in any place that says \"YOUR ANSWER HERE\" with your answers to the questions.\n",
        "\n",
        "Please **do not delete or add any cells**.\n",
        "\n",
        "Before you turn this problem in, make sure everything runs without errors. The easiest way to check this is to restart the kernel and run all cells (in the menubar, select Runtime$\\rightarrow$Restart & Run All).\n",
        "\n",
        "* Groups: You should work in **groups of 2 or 3 people**. (groups of 2 are preferred!)\n",
        "* You are expected to work in Google Colab. If you run the notebooks locally, you may have to solve some issues yourself!\n",
        "* Submit your **fully executed** notebook to Brightspace with file name format: `GroupN_NameSurname1_NameSurname2_NameSurname3.ipynb`\n",
        "* The deadlines for all assignments are on Brightspace.\n",
        "* Deadlines are soft, but make an effort to be on time. We prioritise feedback on assignments that are handed in before the deadline.\n",
        "* Each assignment has 100 points, your grade is your total number of points divided by 10.\n",
        "* The assignments are mandatory, but **do not count** towards your final grade for the course.\n",
        "* For assignments where you have to submit to grand-challenge.org, use team name format `ismi-GroupN-nickname1`.\n",
        "* When working with Google Colab, we advise you to download model checkpoints (.h5 files). This way you don't lose your checkpoint if your session times out. Also, don't forget to connect to a **GPU runtime** when training neural networks!\n",
        "* In Google Colab, you can mount your Google Drive to save files, by clicking the Folder icon on the left, and then click the Mount Drive icon.\n",
        "\n",
        "There are more detailed instructions on Brightspace on how to use Google Colab for the assignments. You can find it here: https://brightspace.ru.nl/d2l/le/content/333312/Home"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fNUassA4xLK"
      },
      "source": [
        "## Students\n",
        "Please fill in this cell with your names, e-mail address and s-numbers. This information will be used to grade your assignment.\n",
        "\n",
        "* [Ivan Slootweg], [s1001424], [ilse.slootweg@ru.nl]\n",
        "* [Elina Antonova], [s1057069], [elina.antonova@ru.nl]\n",
        "* [Sven van der Post], [s1028679], [sven.vanderpost@ru.nl]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fd2b88c7f163b66ada2fd906a769c59f",
          "grade": false,
          "grade_id": "cell-4608f638fa0d0462",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "krDQSspu4xLL"
      },
      "source": [
        "--------\n",
        "# Vessel segmentation in retina fundus images\n",
        "<img src=\"images/21_training.png\" width=\"250\" height=\"250\" align=\"right\">\n",
        "\n",
        "In this assignment we will return to the taks of segmentation of vessels in retina fundus images from assignment 2. This time however, we will solve the problem using deep learning. More specifically, we will explore different **fully convolutional neural networks** and **U-Net**.\n",
        "\n",
        "## Data\n",
        "For this assignment we will use data from the publicly available DRIVE dataset (http://www.isi.uu.nl/Research/Databases/DRIVE/).\n",
        "The DRIVE dataset consists of 40 images, 20 used for training and 20 used for testing. Each case contains:\n",
        "* a fundus (RGB) image\n",
        "* a binary mask, which indicates the area of the image that has to be analyzed (removing black background)\n",
        "* manual annotations of retinal vessels, provided as a binary map\n",
        "\n",
        "## Imports\n",
        "Let's get started by importing libraries needed for this assignment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5ae852dbbc9bcccac4acfb543298a420",
          "grade": false,
          "grade_id": "cell-bff2db9392fbf62b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "S7FFEyB94xLL"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from random import randint\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import requests\n",
        "from tqdm import tqdm_notebook \n",
        "import zipfile\n",
        "import random\n",
        "from tqdm import tnrange\n",
        "from tqdm.notebook import tqdm\n",
        "from pathlib import Path\n",
        "from scipy.ndimage.interpolation import rotate\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # suppress all the TF informational-only messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "837835a4ee31fc1aed2e753be60ffde1",
          "grade": false,
          "grade_id": "cell-725e031b4929a086",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zaKJ_DoV4xLM"
      },
      "outputs": [],
      "source": [
        "#Important to check that TensorFlow 2 is being used (pip freeze). If not: pip install --upgrade tensorflow\n",
        "from tensorflow.keras.models import Model, save_model, load_model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, Cropping2D, Reshape, BatchNormalization\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras.callbacks\n",
        "\n",
        "overwrite=True #to reload already saved models\n",
        "\n",
        "def print_installed():\n",
        "    try:\n",
        "        from pip._internal.operations import freeze\n",
        "    except ImportError:  # pip < 10.0\n",
        "        from pip.operations import freeze\n",
        "\n",
        "    x = freeze.freeze()\n",
        "    for p in x:\n",
        "        print(p)\n",
        "        \n",
        "def print_tensorflow_version():\n",
        "    print(f\"Tensorflow v{tensorflow.__version__}\")\n",
        "    \n",
        "print_tensorflow_version()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5a75f63148454e947f8cbbaa02d84b77",
          "grade": false,
          "grade_id": "cell-c0aec18e833f3bfc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pvkmC0tz4xLM"
      },
      "source": [
        "## Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ffa2cc24e8d93bafc4722c16ae636b38",
          "grade": false,
          "grade_id": "cell-84bc284d4e73d3fd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "q3Y7TaLo4xLN"
      },
      "outputs": [],
      "source": [
        "# Script to download the dataset to your local computer\n",
        "link = 'https://surfdrive.surf.nl/files/index.php/s/Kn4hCF4G919ijr3/download'\n",
        "file_name = \"DRIVE.zip\"\n",
        "if not os.path.isfile(file_name):\n",
        "    with open(file_name, \"wb\") as f:\n",
        "            response = requests.get(link, stream=True)\n",
        "            total_length = response.headers.get('content-length')\n",
        "            if total_length is None: # no content length header\n",
        "                f.write(response.content)\n",
        "            else:\n",
        "                dl = 0\n",
        "                total_length = int(total_length)\n",
        "                chunk_size = 4096\n",
        "                for data in tqdm(response.iter_content(chunk_size=chunk_size), total=total_length//chunk_size, desc='Downloading data'):\n",
        "                    dl += len(data)\n",
        "                    f.write(data)\n",
        "    with zipfile.ZipFile(file_name,\"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"./\")\n",
        "data_folder = 'DRIVE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d05d479bd90def31671a8f282759f2b0",
          "grade": false,
          "grade_id": "cell-eda422115850390b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XsHq9W9A4xLN"
      },
      "outputs": [],
      "source": [
        "os.listdir('./DRIVE/training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e2cd332a10a955fc3b0a22e9b5a69de8",
          "grade": false,
          "grade_id": "cell-0455345504999ff2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "5XLqDdfQ4xLN"
      },
      "source": [
        "------------\n",
        "# Part 1: Fully convolutional neural networks\n",
        "In previous assignments we've seen how neural networks can be applied to classify images into different categories. In this assignment we will explore how the same techniques can be applied to a segmentation task. For segmentation we conceptually solve the same taks as for classification: we can extract a patch around every pixel, and then classify the patch and assign the output back to the pixel location. As you can imagine, many classification steps have to be done to segment a full image: we will be working with images of size 584x565 (329960 pixels), so that would mean we have to apply 329960 classification steps to segment the full image.\n",
        "\n",
        "However, when we move our patch by one pixel to classify the next pixel, a large proportion of the pixels of the new patch are identical to the previous patch, and we will be applying the same convolutions many times over. A trick to obtain a label for all pixels efficiently is to define a network architecture that does not include a fully connected (or dense) part. As the network only contains convolutional filters, the spatial structure is kept intact. Therefore the whole network can be thought of as a single large convolutional filter that can be applied to the whole image at once. This speeds up the classification and allows full image segmentation in milliseconds!\n",
        "\n",
        "During training the same trick can be applied: use a full image as input, and train on all pixel-labels synchronously. In this assignment however, we will initially train the network on patches extracted from random locations in the training data.\n",
        "There are several reasons why this could be useful. To name a few:\n",
        "* In some applications you don't have a label for all pixels, so patches are a necessity.\n",
        "* Less memory is needed during training, which may speed up training time dramatically.\n",
        "* Per training iteration we can use patches from different source images, and apply augmentations on a patch-base, which increases diversity during training, leading to faster convergence and better results.\n",
        "* We could design a sampling strategy so that regions of interests could be seen more often during training. It is also a way to control class balance during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d380e72d6f6861195fbfda6157cbe716",
          "grade": false,
          "grade_id": "cell-bd825821a8023fb0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "noVxFaKD4xLN"
      },
      "source": [
        "## Tasks \n",
        "The tasks you have to perform in Part 1 of this assignment are:\n",
        "1. Create a patch extractor and a batch creator to generate training data for the network.\n",
        "2. Implement and train a fully convolutional neural network.\n",
        "3. Use dilated convolutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cbd04fd441185180cbef374b13fa2ffe",
          "grade": false,
          "grade_id": "cell-1549e77ee1bec48f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "-LUE5PHX4xLN"
      },
      "source": [
        "## Create a training and validation set\n",
        "We will load all training images into memory, and then divide them into two sets: one (called the **training set**) to optimize the weights of the network, and one (**validation set**) to monitor the performance of the network on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "15ad983c2afc5543277480079fbd2a4f",
          "grade": false,
          "grade_id": "cell-cbddb51196e37562",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VCO54lXJ4xLO"
      },
      "outputs": [],
      "source": [
        "def get_file_list(path, ext=''):\n",
        "    return sorted([os.path.join(path, f) for f in os.listdir(path) if f.endswith(ext)])\n",
        "\n",
        "def load_img(path):\n",
        "    return np.array(Image.open(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "33843520a7fb28b3058117efaf97e234",
          "grade": false,
          "grade_id": "cell-3298492e63a68241",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LgX22BEJ4xLO"
      },
      "outputs": [],
      "source": [
        "train_img_files = get_file_list(os.path.join(data_folder, 'training', 'images'), 'tif')\n",
        "train_msk_files = get_file_list(os.path.join(data_folder, 'training', 'mask'), 'gif')\n",
        "train_lbl_files = get_file_list(os.path.join(data_folder, 'training', '1st_manual'), 'gif')\n",
        "\n",
        "train_imgs = [load_img(f) for f in train_img_files]\n",
        "train_msks = [load_img(f) for f in train_msk_files]\n",
        "train_lbls = [load_img(f) for f in train_lbl_files]\n",
        "\n",
        "# we also load test image and masks, to be used later\n",
        "test_img_files = get_file_list(os.path.join(data_folder, 'test', 'images'), 'tif')\n",
        "test_msk_files = get_file_list(os.path.join(data_folder, 'test', 'mask'), 'gif')\n",
        "\n",
        "test_imgs = [load_img(f) for f in test_img_files]\n",
        "test_msks = [load_img(f) for f in test_msk_files]\n",
        "\n",
        "print( \"loading finished\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9bcc40f346975276c7fdf54b48a7836b",
          "grade": false,
          "grade_id": "cell-37592aa4a8793a80",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dJz8ndTn4xLO"
      },
      "source": [
        "Define how many images will be used for validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d332a9f7f3d133baa4f78a028aaee8a9",
          "grade": false,
          "grade_id": "cell-50ad557ff758f8d9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cEo5hYwq4xLP"
      },
      "outputs": [],
      "source": [
        "# Define the number of validation images here:\n",
        "n_validation_imgs = None\n",
        "\n",
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0d055309888b29873b7e6c7e69ae4470",
          "grade": true,
          "grade_id": "cell-0edaf54579eba43f",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yEffyTQj4xLP"
      },
      "outputs": [],
      "source": [
        "\"\"\"DO NOT MODIFY THIS CELL\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e280916f773ccc9bf38d5073bf7ca898",
          "grade": false,
          "grade_id": "cell-df146923a958a306",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "T-SkkreI4xLP"
      },
      "source": [
        "Now we define a class ```DataSet``` that will be used to handle training and validation datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e7f951f1f1fe6a4e907b166ee72fb624",
          "grade": false,
          "grade_id": "cell-e9b15fea3a3c8913",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zPWOfBDB4xLP"
      },
      "outputs": [],
      "source": [
        "class DataSet:\n",
        "    \n",
        "    def __init__(self, imgs, msks, lbls=None):\n",
        "        self.imgs = imgs\n",
        "        self.msks = msks\n",
        "        self.lbls = lbls\n",
        "    \n",
        "    def show_image(self, i):\n",
        "        if self.lbls != None:\n",
        "            f, axes = plt.subplots(1, 3)\n",
        "            for ax, im, t in zip(axes, \n",
        "                                 (self.imgs[i], self.msks[i], self.lbls[i]), \n",
        "                                 ('RGB image', 'Mask','Manual annotation')):\n",
        "                ax.imshow(im, cmap='gray')\n",
        "                ax.set_title(t)\n",
        "        else:\n",
        "            f, axes = plt.subplots(1, 2)\n",
        "            for ax, im, t in zip(axes, \n",
        "                                 (self.imgs[i], self.msks[i]), \n",
        "                                 ('RGB image', 'Mask')):\n",
        "                ax.imshow(im, cmap='gray')\n",
        "                ax.set_title(t)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "41a884a969154fe78729f61505adb507",
          "grade": false,
          "grade_id": "cell-8aa60f366460ad67",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_o10TFJD4xLP"
      },
      "outputs": [],
      "source": [
        "# use the first images as validation\n",
        "validation_data = DataSet(train_imgs[:n_validation_imgs], train_msks[:n_validation_imgs], train_lbls[:n_validation_imgs])\n",
        "\n",
        "# the rest as training\n",
        "train_data = DataSet(train_imgs[n_validation_imgs:], train_msks[n_validation_imgs:], train_lbls[n_validation_imgs:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "468251f27a472854e3d8b2025c3a5308",
          "grade": false,
          "grade_id": "cell-e4eec0f464627ce7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "avoZQULc4xLQ"
      },
      "source": [
        "Let's inspect some of the loaded images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ENzdEqnC4xLQ"
      },
      "outputs": [],
      "source": [
        "matplotlib.rcParams['figure.figsize'] = (20, 12)\n",
        "validation_data.show_image(0) # change this parameter to try a few images\n",
        "train_data.show_image(0) # change this parameter to try a few images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3c6556c1b5e3f7d23c597d0f66b7d57a",
          "grade": false,
          "grade_id": "cell-eaad1bcf78d1ef3b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "CIozYKJL4xLQ"
      },
      "source": [
        "## Build a patch extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "93637e72117848bdd75262d90c9d0b53",
          "grade": false,
          "grade_id": "cell-b8a159c690d174e1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "SEM1BgtX4xLQ"
      },
      "source": [
        "In this assignment we are going to implement a ```PatchExtractor``` class, which extract random patches from a list of images.\n",
        "This means that you don't need to create a dataset beforehand and then use it to train you network, but you will just have a list of training images and annotation segmentations available, and patches will be extracted **on-the-fly** during training. For each example, you will need to generate an image patch and a corresponding label patch (patch with segmentation annotation) given a patch center location (y, x) and a predefined patch size (h, w). The generated image and label patches should have the same dimension.\n",
        "This strategy allows to save time in the preparation of your *static* dataset, and allows the use of a *dynamic* generation of batches, where data augmentation can also be applied on-the-fly.\n",
        "\n",
        "Note that this approach allows to test different strategies of data augmentation without the need for making a new dataset from scratch all the time. For now, we will only implement one kind of data augmentation in the ```get_patch``` method: **horizontal flipping**. The event will occur at random such that for each patch location, there is a 50% chance it gets flipped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f7a6d4fbf7dea7c094f2ba90068fc904",
          "grade": false,
          "grade_id": "cell-33c5fefc7b18cdd9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KnLGMiF94xLQ"
      },
      "outputs": [],
      "source": [
        "# Implement the get_patch method below:\n",
        "\n",
        "class PatchExtractor:\n",
        "\n",
        "    def __init__(self, patch_size, horizontal_flipping=True):\n",
        "        self.patch_size = patch_size\n",
        "        self.horizontal_flipping = horizontal_flipping\n",
        "        \n",
        "        \n",
        "    def get_patch(self, image, mask, location):\n",
        "        ''' \n",
        "        image: a numpy array representing the input image,\n",
        "        mask: a numpy array representing the corresponding segmentation annotation\n",
        "        location: a tuple with an y and x coordinate\n",
        "        \n",
        "        return a patch from the image at `location`, representing the center of the patch, and the corresponding label patch\n",
        "        if self.horizontal_flipping = True, there is a 50% chance the patch is horizontally flipped  \n",
        "        we will not rotate it or perform other augmentations for now to speed up the training process\n",
        "        '''\n",
        "        y, x = location\n",
        "        py, px = self.patch_size\n",
        "        \n",
        "        \n",
        "        \n",
        "        # - patch should be a numpy array of size <h, w>\n",
        "        # - the patch should be normalized (intensity values between 0-1)\n",
        "        \n",
        "        img_patch = None\n",
        "        label_patch = None\n",
        "        # YOUR CODE HERE\n",
        "        \n",
        "        # - if self.flipping = True, there should be a 50% chance to apply a horizontal flip to the patch  \n",
        "        if self.horizontal_flipping:\n",
        "            do_flipping = None\n",
        "            \n",
        "            # YOUR CODE HERE\n",
        "            \n",
        "            # - if do_flipping == True, flip the patch horizontally\n",
        "            if do_flipping:\n",
        "                img_patch_flipped = None\n",
        "                label_patch_flipped = None\n",
        "\n",
        "                # YOUR CODE HERE\n",
        "\n",
        "                img_patch = img_patch_flipped\n",
        "                label_patch = label_patch_flipped\n",
        "        \n",
        "        \n",
        "        assert img_patch.ndim == label_patch.ndim\n",
        "        return img_patch, label_patch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f6a971871df36e875bd89ac9557318a4",
          "grade": true,
          "grade_id": "cell-53a16b5c886630d6",
          "locked": true,
          "points": 15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IHnK4bkN4xLQ"
      },
      "outputs": [],
      "source": [
        "'''DO NOT MODIFY THIS CELL'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a0e7ebccac54e588e86e17d72f8297ba",
          "grade": false,
          "grade_id": "cell-4a56e3a5247c8266",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "V6MRf3-M4xLR"
      },
      "source": [
        "Let's test our patch extractor! By repeatedly executing the cell below, you should be able to see different augmentations of the same patch. The dot in the images represents the center of the patch, which is the pixel we are going to classify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "63c13d1da9728de47201d8dbf8dff831",
          "grade": false,
          "grade_id": "cell-8d671c5c17fb38fd",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qodd1BQg4xLR"
      },
      "outputs": [],
      "source": [
        "patch_size = (None, None) # Set the size of the patches as a tuple (height, width) \n",
        "\n",
        "img_index = None # choose an image to extract the patch from\n",
        "location = (None, None) # define the location of the patch (y, x) - coordinate\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0355cdeb23b435a425f10905db1191b6",
          "grade": true,
          "grade_id": "cell-c56f412e4c8f6123",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8jk0uFZB4xLR"
      },
      "outputs": [],
      "source": [
        "'''DO NOT MODIFY THIS CELL'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6fr1fsPQ4xLR"
      },
      "outputs": [],
      "source": [
        "patch_extractor = PatchExtractor(patch_size, True)\n",
        "\n",
        "matplotlib.rcParams['figure.figsize'] = (5, 5)\n",
        "image_patch, label_patch = patch_extractor.get_patch(train_data.imgs[img_index], np.expand_dims(train_data.lbls[img_index], -1), location)\n",
        "label_patch = np.repeat(label_patch, 3, axis=-1)\n",
        "f, axes = plt.subplots(1, 2)\n",
        "axes[0].imshow(image_patch)\n",
        "axes[0].set_title('image at {}'.format(location))\n",
        "axes[1].imshow(label_patch)\n",
        "axes[1].set_title('mask at {}'.format(location))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bd692173f86b0be9a4695b9491237303",
          "grade": false,
          "grade_id": "cell-0836056cd89d19bc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "78-Yrz-u4xLR"
      },
      "source": [
        "## Build a batch creator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cae79336225d3dec887e34c465c2d31e",
          "grade": false,
          "grade_id": "cell-545f4a389ec6cf79",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "h71oFajp4xLR"
      },
      "source": [
        "The BatchCreator will allow us to generate batches to train on. These batches contain a set of (class-balanced) samples or patches, and their corresponding labels. The data returned by the ```BatchCreator``` can directly be fed into the neural network for training or classification. \n",
        "\n",
        "First we define a useful function for padding images with a zero-border:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f24f5d29a53111e01d03be03d0fdd331",
          "grade": false,
          "grade_id": "cell-d0bee08dd587a76d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "X1fCMdk84xLR"
      },
      "outputs": [],
      "source": [
        "def pad(images, patch_size):\n",
        "    '''\n",
        "    images: list of images (numpy arrays)\n",
        "    returns a padded version of the images, with a border of half the patch_size around each image\n",
        "    '''\n",
        "    half_py, half_px = [p//2 for p in patch_size]\n",
        "    paddings = ((0, 0), (half_py, half_py), (half_px, half_px), (0, 0))\n",
        "    return np.pad(np.array(images), pad_width=paddings, mode='constant') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "27ad3dd2dac7d3408224a5fc06c00b40",
          "grade": false,
          "grade_id": "cell-1e90bf5a833d296a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "v41-g1FA4xLR"
      },
      "source": [
        "Now, implement the ```create_batch``` method in the ```BatchCreator``` class. It should return the patches and labels (```x_data``` and ```y_data```) where ```x_data``` denotes the image patch, and ```y_data``` is the corresponding labels. The idea is to predict whether a pixel is vessel or not by feeding the image patch surrounding the pixel to the network. So here the labels are the one-hot encoding class vectors for the pixels at the patch center. Previously, you have implemented a patch extractor that gives you an image and label patch. You should be able to compute the pixel labels at patch center from the label patch.\n",
        "We also provide you an implementation of a class balanced patch location sampler, which will compute locations to extract patches such that half of the locations are foreground pixels (vessels) and the other half of the locations are background pixels (inside the fundus mask, but not vessels).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "886161f354ba7e1c0774e6d7aee4440c",
          "grade": false,
          "grade_id": "cell-feeaa651b8aefaeb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HKzKy8UG4xLS"
      },
      "outputs": [],
      "source": [
        "class BalancedSampler:\n",
        "\n",
        "    def __init__(self, lbls, msks):\n",
        "        # pre calculate the positive and negative indices\n",
        "        lbls = np.squeeze(lbls, 3)\n",
        "        msks = np.squeeze(msks, 3)\n",
        "        self.p_idxs = np.asarray(np.where(lbls > 0)).T.tolist()\n",
        "        self.n_idxs = np.asarray(np.where((msks > 0) & ~(lbls > 0))).T.tolist()\n",
        "\n",
        "    def generate_sample_locations(self, batch_size):\n",
        "        # generate locations half from the positive set and half from the negative set\n",
        "        p_locations = random.sample(self.p_idxs, batch_size // 2)\n",
        "        n_locations = random.sample(self.n_idxs, batch_size - batch_size // 2)\n",
        "        locations = np.vstack([p_locations, n_locations])\n",
        "        return locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "aae95912246f20c4ab515a2ae5c431b0",
          "grade": false,
          "grade_id": "cell-2d02f3f687cc0c20",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bI0P0ogt4xLS"
      },
      "outputs": [],
      "source": [
        "class BatchCreator:\n",
        "    \n",
        "    def __init__(self, patch_extractor, dataset, border_pad_size):\n",
        "        self.patch_extractor = patch_extractor\n",
        "\n",
        "        # the images are padded with half the patch-size around the border\n",
        "        # this way, we don't risk extracting patches from the border, that extend beyond the original image\n",
        "        self.imgs = pad(dataset.imgs, border_pad_size)\n",
        "        self.lbls = pad(np.expand_dims(dataset.lbls, 3), border_pad_size)\n",
        "        self.msks = pad(np.expand_dims(dataset.msks, 3), border_pad_size)\n",
        "        self.patch_location_sampler = BalancedSampler(self.lbls, self.msks)\n",
        "\n",
        "    def create_batch(self, batch_size):\n",
        "        '''\n",
        "        returns a class-balanced array of patches (x) with corresponding labels (y) in one-hot structure\n",
        "        '''\n",
        "        x_data = np.zeros((batch_size, *self.patch_extractor.patch_size, 3))\n",
        "        y_data = np.zeros((batch_size, 1, 1, 2))  # one-hot encoding\n",
        "        locations = self.patch_location_sampler.generate_sample_locations(batch_size)\n",
        "        \n",
        "        # YOUR CODE HERE\n",
        "      \n",
        "        return x_data, y_data\n",
        "        \n",
        "    def get_generator(self, batch_size):\n",
        "        '''returns a generator that will yield batches infinitely'''\n",
        "        while True:\n",
        "            yield self.create_batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8ebe588dc996d1346f658439c7b97e4a",
          "grade": true,
          "grade_id": "cell-db2ced9bc93ce61a",
          "locked": true,
          "points": 15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MN3mC1Xr4xLS"
      },
      "outputs": [],
      "source": [
        "'''DO NOT MODIFY THIS CELL'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "96908f29b2e4fc1e276fcdccd5acd196",
          "grade": false,
          "grade_id": "cell-ddc5c165fb535073",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "TS7hqE384xLS"
      },
      "source": [
        "Let's test our BatchCreator! Half of the patches in the visualization below should represent vessel patches (having a vessel in the center of the patch). The other half should represent background patches (no vessel in the center of the patch). The dot in the images represents the center of the patch, which is the pixel we are going to classify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "44624fd679a0b63a8e2d677718375fa6",
          "grade": false,
          "grade_id": "cell-287693018316eadd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VJkgD7AV4xLS"
      },
      "outputs": [],
      "source": [
        "batch_creator = BatchCreator(patch_extractor, train_data, patch_extractor.patch_size)\n",
        "\n",
        "# create a batch\n",
        "x, y = batch_creator.create_batch(28)\n",
        "# visualize it\n",
        "matplotlib.rcParams['figure.figsize'] = (20, 12)\n",
        "f, axes = plt.subplots(4, 7)\n",
        "i = 0;\n",
        "for ax_row in axes:\n",
        "    for ax in ax_row:\n",
        "        ax.imshow(x[i])\n",
        "        ax.set_title('class: {}'.format(np.argmax(y[i, 0, 0])))\n",
        "        ax.scatter(*[p/2 for p in patch_extractor.patch_size], alpha=0.5)\n",
        "        i += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f7add8daca38f62e59a6818b53d02501",
          "grade": false,
          "grade_id": "cell-debce8766d9219eb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "o_5qvCFn4xLS"
      },
      "source": [
        "## Build and train the first fully convolutional network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "eba602d83dece1a4bf2623f3f7a06069",
          "grade": false,
          "grade_id": "cell-8a24520e7bda4ba9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XFhu_4OW4xLS"
      },
      "source": [
        "We will now start with defining our initial network architecture in Keras.\n",
        "\n",
        "This is another package to do deep learning package in python, a popular alternative to PyTorch. Here is a short example of how you define a simple network with Keras:\n",
        "```python\n",
        "from keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(784,))\n",
        "x = layers.Dense(32, activation='relu')(inputs)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "predictions = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=predictions)\n",
        "model.compile(...)\n",
        "```\n",
        "For more information, check out https://keras.io/guides/functional_api/\n",
        "\n",
        "What is important to train a fully convolutional neural network on patches, is that **the size of the feature maps within the network goes down to exactly 1x1 for the final feature map**. \n",
        "We will therefore use **valid** convolutions (in contrast to **same** convolutions) and pooling operations to reduce the size of the feature maps.\n",
        "This requires some computation, but luckily it is pretty straightforward:  \n",
        "\n",
        "If we define:\n",
        "```\n",
        "i = Input featuremap size\n",
        "o = Output featuremap size \n",
        "f = Convolution filter size \n",
        "m = Pooling size\n",
        "```\n",
        "Then:\n",
        "\n",
        "Output size of a feature map after convolution with a convolution filter of size f:\n",
        "```python\n",
        "o = i - (f - 1)\n",
        "```\n",
        "Output size of a feature map after pooling of size m:\n",
        "```python\n",
        "o = floor(i/m)\n",
        "```\n",
        "\n",
        "### Model definition\n",
        "Let's define a baseline model:\n",
        "* input layer \n",
        "* 32 filters of 4x4\n",
        "* 32 filters of 3x3\n",
        "* pooling\n",
        "* 64 filters of 3x3\n",
        "* 64 filters of 3x3\n",
        "* pooling\n",
        "* 128 filters of 3x3\n",
        "* 64 filters of 1x1\n",
        "* 2 filters of 1x1 \n",
        "\n",
        "After every convolution we will apply a **relu** non-linearity. The last layer should have a **softmax** non-linearity to transform the 2 filters in probabilities for the vessel and background class.  \n",
        "\n",
        "The reason to start with the less common 4x4 convolutions, is that we wish to define a patch-size that has an odd number of pixels (so that we can define a single center pixel that corresponds with the label). At the same time, we want the input to the pooling layers to be even, so we don't exclude the pixels around the border. The 1x1 convolutions in the deeper layers act as the dense part of a classification network: we no longer take contextual information into account, but only do recombination of features. The final two filters represent the two classes background and vessel.\n",
        "\n",
        "**NOTE**: Since a fully-convolutional network can process input patches of (almost) any size, we should not hard-code a specific size in the ```Input``` layer. The way of doing this is to define the height and the width of input patches as ```None```. The same trick is used to avoid specifying a mini-batch size, which can be changed arbitrarily. We do hard-code the presence of 3 channels, because we are going to process RGB images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "678bc094eac95ea40e17c024157a7480",
          "grade": false,
          "grade_id": "cell-28032abc9707b8be",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VXKWc29Y4xLT"
      },
      "outputs": [],
      "source": [
        "## DEFINE THE ABOVE DESCRIBED MODEL HERE\n",
        "x_in = Input(batch_shape=(None, None, None, 3)) # DO NOT REPLACE None HERE! It is actually needed!!!\n",
        "\n",
        "\n",
        "x_out = None # this is the output fo your network, used later on in this notebook\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "065f09889287e5b4295d2430d09eb497",
          "grade": true,
          "grade_id": "cell-632ed372172523b9",
          "locked": true,
          "points": 15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HLPuuYsh4xLT"
      },
      "outputs": [],
      "source": [
        "'''DO NOT MODIFY THIS CELL'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1412765d0e503e46f9bcd908e0e4071c",
          "grade": false,
          "grade_id": "cell-89c5a2454a2f3841",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "yOG-cPtj4xLT"
      },
      "source": [
        "## Define the loss, compile the model and define the logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9c696605bf2c80dba35a5c9739e31d00",
          "grade": false,
          "grade_id": "cell-6f8a19487a666e90",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "tpAHlli44xLT"
      },
      "source": [
        "For this assignment we will use the cross-entropy loss (sometimes also referred to as log-loss). In this case it is equivalent to the mean log of the differences between true labels and the predicted labels for a given batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe60d8398795d880ef730a6979d9a075",
          "grade": false,
          "grade_id": "cell-62e1088471cafca8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "elDVMJ234xLT"
      },
      "outputs": [],
      "source": [
        "model_1 = Model(x_in, x_out)\n",
        "\n",
        "# define the optimizer. etc\n",
        "learning_rate = 1e-4\n",
        "optimizer = Adam(learning_rate)\n",
        "model_1.compile(optimizer, loss='categorical_crossentropy')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "89e3fdd4d0a9d7f6d8f5b958fe88e98e",
          "grade": false,
          "grade_id": "cell-5f2c04611a2817f6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ucP0CIMu4xLT"
      },
      "source": [
        "Here we define a logger class, that will store useful data througout the training procedure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "faca9cda067b740c4ecad08815d359f4",
          "grade": false,
          "grade_id": "cell-2e40ccdad575ef6f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6ppVzSz24xLT"
      },
      "outputs": [],
      "source": [
        "def downscale(images, stride):\n",
        "    # Downscale if the network does pooling\n",
        "    return np.array(images)[:, ::stride, ::stride]\n",
        "\n",
        "def calculate_dice(x, y):\n",
        "    '''returns the dice similarity score, between two boolean arrays'''\n",
        "    return 2 * np.count_nonzero(x & y) / (np.count_nonzero(x) + np.count_nonzero(y))\n",
        "    \n",
        "class Logger(tensorflow.keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, validation_data, patch_size, stride=1):\n",
        "        self.val_imgs = pad(validation_data.imgs, patch_size) / 255.\n",
        "        self.val_lbls = downscale(validation_data.lbls, stride) > 0\n",
        "        self.val_msks = downscale(validation_data.msks, stride) > 0\n",
        "         \n",
        "        self.losses = []\n",
        "        self.dices = []\n",
        "        self.best_dice = 0\n",
        "        self.best_model = None\n",
        "    \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "    \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        dice = self.validate()\n",
        "        self.dices.append([len(self.losses), dice])\n",
        "        if dice > self.best_dice:\n",
        "            self.best_dice = dice\n",
        "            self.best_model = self.model.get_weights()\n",
        "        self.plot()\n",
        "           \n",
        "    def validate(self):\n",
        "        predicted_lbls = self.model.predict(self.val_imgs, batch_size=1)[:,:,:,1]>0.5\n",
        "        x = self.val_lbls[self.val_msks]\n",
        "        y = predicted_lbls[self.val_msks]\n",
        "        return calculate_dice(x, y)\n",
        "    \n",
        "    def plot(self):\n",
        "        clear_output()\n",
        "        N = len(self.losses)\n",
        "        train_loss_plt, = plt.plot(range(0, N), self.losses)\n",
        "        dice_plt, = plt.plot(*np.array(self.dices).T)\n",
        "        plt.legend((train_loss_plt, dice_plt), \n",
        "                   ('training loss', 'validation dice'))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a2494477657f2d2cd737af322ceff800",
          "grade": false,
          "grade_id": "cell-d2342c9da74fd95d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "UfOJZuVn4xLT"
      },
      "source": [
        "Now you have to define some parameters, which are needed to train your network.\n",
        "To do validation during training, we need to define the downscaling factor (which we call ```stride```) due to pooling of our network. That is: how much lower is the resolution of the output compared to the input?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9c4372954b4e0d2768473554905f2e21",
          "grade": false,
          "grade_id": "cell-239acf7f886bbcdb",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "44kE7Hc-4xLU"
      },
      "outputs": [],
      "source": [
        "patch_size = (None, None)       # should be a tuple of width, height corresponding to your network architecture \n",
        "batch_size = None               # pick a reasonable batch-size (e.g. power-of-two in the range 32, 64, 128, 256)\n",
        "\n",
        "# To let the network converge to a reasonable state, steps_per_epoch * epochs should be around 5000 to 10000\n",
        "\n",
        "steps_per_epoch = None         # how many steps per epoch?\n",
        "epochs = None                  # how many epochs? \n",
        "stride = None                  # what is the downscaling factor of your network?\n",
        "# YOUR CODE HERE\n",
        "flipping = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "151db9ee1677662828ce6395e7ced759",
          "grade": true,
          "grade_id": "cell-3c8dd9003ea554fb",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WRbDL17W4xLU"
      },
      "outputs": [],
      "source": [
        "'''DO NOT MODIFY THIS CELL'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4e02c7b69b6bccdfb7f427783f6b1f9a",
          "grade": false,
          "grade_id": "cell-b6bda8117289c36c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "V58K8iWe4xLU"
      },
      "source": [
        "What is the correct value for our downsampling factor (stride) and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2e1d1a967757e551ff8881a03d13713f",
          "grade": true,
          "grade_id": "cell-37b79e33a6015c9f",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Y_bLbOLF4xLU"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b017df7d07dfc9656f76dd16a46150f0",
          "grade": false,
          "grade_id": "cell-18ea55dd8717de11",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Avvb0Mge4xLU"
      },
      "source": [
        "Now we use all the classes defined so far to initialize data that will be used for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "297dec40a31d4c4dac2d7acac64225b7",
          "grade": false,
          "grade_id": "cell-afa0dcd2453cd1fa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zmnaluhT4xLU"
      },
      "outputs": [],
      "source": [
        "patch_extractor = PatchExtractor(patch_size, horizontal_flipping=True)\n",
        "batch_creator = BatchCreator(patch_extractor, train_data, patch_size)\n",
        "generator = batch_creator.get_generator(batch_size)\n",
        "logger_1 = Logger(validation_data, patch_size, stride=stride)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe6e87f2afb516a67f7e32909f51ff4a",
          "grade": false,
          "grade_id": "cell-441655bcb886b790",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5l3rZbsc4xLU"
      },
      "outputs": [],
      "source": [
        "if overwrite or not Path('./model_1').exists():\n",
        "    model_1.fit_generator(generator=generator, \n",
        "                      steps_per_epoch=steps_per_epoch, \n",
        "                      epochs=epochs, \n",
        "                      callbacks=[logger_1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "616a744e3f5eea4a8f5cb283d17ee509",
          "grade": false,
          "grade_id": "cell-998a1104be2f265d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9o9-P4za4xLU"
      },
      "source": [
        "## Check results on the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fa1b4c68e6f33f65893bdbb9ddc3e6ea",
          "grade": false,
          "grade_id": "cell-9fbb40e78f30936a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "AtYe11Ge4xLV"
      },
      "source": [
        "Now let's apply the trained model to the validation data to get an idea how well the network is performing. We will define the function ```process_basic``` below to apply the model to a dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "64dcfa9e1ceffdf95652719b44b20565",
          "grade": false,
          "grade_id": "cell-2a1c929444eaf3d6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YXZwywwc4xLV"
      },
      "outputs": [],
      "source": [
        "def process_basic(model, dataset, stride=1):\n",
        "    \n",
        "    # pad the original images, so we don't loose the borders in our output\n",
        "    imgs = pad(dataset.imgs, patch_size) / 255.\n",
        "    \n",
        "    # downscale the label and masks if needed (to get the same resolution as the output)\n",
        "    lbls = downscale(dataset.lbls, stride) > 0\n",
        "    msks = downscale(dataset.msks, stride) > 0\n",
        "    \n",
        "    # apply our model to the images\n",
        "    output = model.predict(imgs, batch_size=1)[:,:,:,1]\n",
        "\n",
        "    return lbls, msks, output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "50887515517fde1cb1191d9e0e42aedd",
          "grade": false,
          "grade_id": "cell-d1f18035f3db4151",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "vOPPGoK74xLV"
      },
      "source": [
        "We will use the following function to visually inspect the results and calculate a dice-score for each image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6f2f05b6e8d890100bc9d0af4eb5fb86",
          "grade": false,
          "grade_id": "cell-aeb4437e4de953ac",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HkzaVEYA4xLV"
      },
      "outputs": [],
      "source": [
        "def check_results(imgs, lbls, msks, output, threshold=0.5):\n",
        "\n",
        "    dices = []\n",
        "    for i, (img, lbl, msk, raw_output) in enumerate(zip(imgs, lbls, msks, output)):\n",
        "        \n",
        "        final_output = raw_output > threshold\n",
        "        \n",
        "        dice = calculate_dice(final_output[msk], lbl[msk])\n",
        "        dices.append(dice)\n",
        "        print('image:', i, 'dice', dice)\n",
        "        \n",
        "        # plot the results\n",
        "        matplotlib.rcParams['figure.figsize'] = (15, 6)\n",
        "        f, axes = plt.subplots(1, 4)\n",
        "        for ax, im, t in zip(axes, \n",
        "                             (img, raw_output, final_output, lbl), \n",
        "                             ('RGB image', 'Soft prediction', 'Thresholded', 'Ground truth')):\n",
        "            ax.imshow(im, cmap='gray')\n",
        "            ax.set_title(t)\n",
        "        plt.show()\n",
        "        \n",
        "    print('mean dice', np.mean(dices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "31cd2d69049571784ba40e9218b04698",
          "grade": false,
          "grade_id": "cell-c7dfa16db1ae77d4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "OgAbGHGa4xLV"
      },
      "source": [
        "Now we load the best model (based on the validation dice score during training), and check the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2bcf99f73cacba602d02ba88e31fec2a",
          "grade": false,
          "grade_id": "cell-7eb01e8c8e0d3cc7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RVztTTty4xLV"
      },
      "outputs": [],
      "source": [
        "#model_1.load('./model_1')\n",
        "if overwrite or not Path('./model_1').exists():\n",
        "    model_1.set_weights(logger_1.best_model)\n",
        "    model_1.save('./model_1')\n",
        "else:\n",
        "    model_1 = load_model('./model_1')\n",
        "\n",
        "lbls, msks, output =  process_basic(model_1, validation_data, stride=stride)\n",
        "check_results(validation_data.imgs, lbls, msks, output, threshold=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "927be18871af1b6c660548c28ed46ea0",
          "grade": false,
          "grade_id": "cell-9cbd9d548ffcb075",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "V2YfkZwY4xLV"
      },
      "source": [
        "## Use dilated convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4ba7c4d499bb0e65e759282a3caff6fb",
          "grade": false,
          "grade_id": "cell-0afc4a2846deb755",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "p6c8YAAZ4xLV"
      },
      "source": [
        "<img align=\"right\" width=\"300\" src=\"images/dilation.gif\">\n",
        "\n",
        "You can see that the label image predicted by our network has a **much lower resolution** then the input image.\n",
        "This is due to the pooling operations that we used in our network. One solution to this would be to completely remove the pooling layers. For this, however, we would need to train using even smaller patches as input, reducing the context even more.\n",
        "\n",
        "To get state-of-the-art results, it is normally necessary to include a **larger context**. If we wish to do this without introducing pooling operations or increasing the complexity of the network too much, we have another option: dilated convolutions.\n",
        "\n",
        "Dilated convolutions work like regular convolutions, but introduce a spacing between the parameters of the filter. This way, they expand the area covered by the filter (often referred to as the **receptive field**). Unlike pooling operations, they do not reduce the resolution of the feature maps. Let's experiment with them, and define a new network architecture that includes dilated convolutions. See the image to the right for an example of a 3x3 convolution filter with dilation rate 2 (image taken from https://github.com/vdumoulin/conv_arithmetic ).\n",
        "\n",
        "Implement the following network\n",
        "* input layer \n",
        "* 32 filters of 3x3\n",
        "* 32 filters of 3x3\n",
        "* 64 filters of 3x3, dilation rate 2\n",
        "* 64 filters of 3x3, dilation rate 4\n",
        "* 128 filters of 3x3, dilation rate 8\n",
        "* 64 filters of 1x1\n",
        "* 2 filters of 1x1 \n",
        "\n",
        "Note:\n",
        "1. kernel weights initializer should be `'he_uniform'`\n",
        "2. activation (except for final softmax) should be `'relu'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c30058e154d0a12c2192e0efce58152b",
          "grade": false,
          "grade_id": "cell-a746a28425600fde",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ic7IfHAQ4xLW"
      },
      "outputs": [],
      "source": [
        "x_in = Input(batch_shape=(None, None, None, 3))\n",
        "x_out = None\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3e97224ba528db0ec80693c10b88859a",
          "grade": true,
          "grade_id": "cell-4b2bdb1b7248dfca",
          "locked": true,
          "points": 15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DZgL11lM4xLW"
      },
      "outputs": [],
      "source": [
        "'''DO NOT MODIFY THIS CELL'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2fc67d8eab30bd62000eb5409f5f82c3",
          "grade": false,
          "grade_id": "cell-9a672cbc3ce586b2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FSeJ7TOX4xLW"
      },
      "outputs": [],
      "source": [
        "model_2 = Model(x_in, x_out)\n",
        "model_2.compile(optimizer, loss='categorical_crossentropy')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "dcdd384ec153d31d122c9d2e04abfccb",
          "grade": false,
          "grade_id": "cell-81ee7b4a2845ea0f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "SqQBZsMH4xLW"
      },
      "source": [
        "Set the new patch_size and stride for this network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ae505a4a01e7150f31e2c4d27edf50ed",
          "grade": false,
          "grade_id": "cell-b2f5979f3fb91fff",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8TegAY_24xLW"
      },
      "outputs": [],
      "source": [
        "patch_size = None \n",
        "stride = None\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3918577b7b207f2eed83b2c4b4818fea",
          "grade": true,
          "grade_id": "cell-91b6c0c2020151fe",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kcRUqJR44xLW"
      },
      "outputs": [],
      "source": [
        "'''DO NOT MODIFY THIS CELL'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2c74ace0b5749ae10e8c16d8609ec3a6",
          "grade": false,
          "grade_id": "cell-96cc6d69e0342ead",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_pQ7y-EA4xLW"
      },
      "outputs": [],
      "source": [
        "patch_extractor = PatchExtractor(patch_size, horizontal_flipping=True)\n",
        "batch_creator = BatchCreator(patch_extractor, train_data, patch_size)\n",
        "\n",
        "patch_generator = batch_creator.get_generator(batch_size)\n",
        "\n",
        "logger_2 = Logger(validation_data, patch_size, stride=stride)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6de09e59fbe5bfe95a1f60be986869fa",
          "grade": false,
          "grade_id": "cell-a37d88c6ec0c3a0a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "f5QBbwF-4xLW"
      },
      "outputs": [],
      "source": [
        "if overwrite or not Path('./model_2').exists():\n",
        "    model_2.fit_generator(generator=patch_generator, \n",
        "                      steps_per_epoch=steps_per_epoch, \n",
        "                      epochs=epochs, \n",
        "                      callbacks=[logger_2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "17c54fa610250b818b385429911490ef",
          "grade": false,
          "grade_id": "cell-5400238f04fedd0a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "l-38Tbjm4xLW"
      },
      "source": [
        "Again, we will load the best model (the one that achieved highest Dice score during training) and inspect the results on the validation set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d53e9bd52b691ee38af6179a6bcf758a",
          "grade": false,
          "grade_id": "cell-b5128e15e35214a8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iY3dpmuq4xLX"
      },
      "outputs": [],
      "source": [
        "if overwrite or not Path('./model_2').exists():\n",
        "    model_2.set_weights(logger_2.best_model)\n",
        "    model_2.save('./model_2')\n",
        "else:\n",
        "    print('loading saved model')\n",
        "    model_2 = load_model('./model_2')\n",
        "lbls, msks, output = process_basic(model_2, validation_data)\n",
        "check_results(validation_data.imgs, lbls, msks, output, threshold=0.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "75d7ab657e1839012fbc7cb383fef377",
          "grade": false,
          "grade_id": "cell-e8c1afb181648e2f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "iZZP4gx-4xLX"
      },
      "source": [
        "## Submit test results to grand-challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c163b8fa221e9f82463cf818569468be",
          "grade": false,
          "grade_id": "cell-00576bbcf434f9c9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5nyTewcY4xLX"
      },
      "source": [
        "Now you can process images in the test set and submit your results to grand-challenge.\n",
        "You can tune the threshold and (optionally) apply the mask before submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a1db750989dc53c1b20f03b22068e16c",
          "grade": false,
          "grade_id": "cell-d630608cd83a595a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8ezH-6iF4xLX"
      },
      "outputs": [],
      "source": [
        "# define output folder\n",
        "result_output_folder = './results'\n",
        "if not os.path.exists(result_output_folder):\n",
        "    os.makedirs(result_output_folder)\n",
        "\n",
        "# threshold to select segmented pixels\n",
        "threshold = 0.5\n",
        "\n",
        "# pad all images in the test set\n",
        "imgs = pad(test_imgs, patch_size) / 255.\n",
        "   \n",
        "# apply our model to the images\n",
        "output = model_2.predict(imgs, batch_size=1)[:,:,:,1]\n",
        "\n",
        "# save all output masks as png images\n",
        "for i in range(output.shape[0]):\n",
        "\n",
        "    # output has to be:\n",
        "    # - thresholded\n",
        "    # - converted to grayscale\n",
        "    segmentation = 255 * (output[i, :, :].squeeze() > threshold).astype(int)\n",
        "    \n",
        "    # save to disk\n",
        "    im = Image.fromarray(segmentation.astype('uint8'))\n",
        "    im.save(os.path.join(result_output_folder, \"{}.png\".format(i + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "29f9bd5976aa4bb2d312e163166674c9",
          "grade": false,
          "grade_id": "cell-29f193005d3a3412",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CZMXnl1d4xLX"
      },
      "outputs": [],
      "source": [
        "shutil.make_archive('results', 'zip', result_output_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "33f7bfcb1ab9ad1722e03f9c7d32563a",
          "grade": false,
          "grade_id": "cell-6a48014fefd5973c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4-Fff1ax4xLX"
      },
      "source": [
        "------------\n",
        "# Part 2: U-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "950e6787f6de59fdc5fe3527816328e4",
          "grade": false,
          "grade_id": "cell-971d0e0336529fc3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Jm8UgwoC4xLX"
      },
      "source": [
        "As you might have observed, the use of dilated convolutions in the fully-convoutional network gives a full-resolution output, but the processing is slow due to the large feature maps. In the second part of this assignment, we are going to work with **U-Net** for retina vessels segmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "496508486dfc99663995b651d92c62ad",
          "grade": false,
          "grade_id": "cell-304c34335e62e27f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "xURq_yLE4xLX"
      },
      "source": [
        "## Tasks\n",
        "These are the main tasks of the second part of this assignment:\n",
        "1. Implement a batch creator that generates image and label patches for U-Net training.\n",
        "2. Train a baseline U-Net model.\n",
        "3. Improve the U-Net implementation to increase performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f773cf8900ef4ae76f333af08e465f82",
          "grade": false,
          "grade_id": "cell-3116778134478005",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "AoAC4_5N4xLY"
      },
      "source": [
        "## Implement a batch creator that generates image and mask patches for U-Net training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a9c581e28d2be0db9a34735d7f8385ba",
          "grade": false,
          "grade_id": "cell-4aa99e5f1a03f672",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "m83hoGIB4xLY"
      },
      "source": [
        "We implement here the ``UNetBatchCreator``. Note that our previous model predicted a label for the center pixel, given the surrounding image patch. Now the U-Net model will predict labels for all pixels in a patch. Therefore, you need to implement a batch creator to generate batches of image patches and the correspoding whole segmentation annotation patches. For simplicity, this creator makes use of the previous  ``BalancedSampler``, although it is not relevant anymore that center pixels of the patches belong to positive or negative samples in a balanced way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "39b73cac0aa1347e892d6921a06e9a75",
          "grade": false,
          "grade_id": "cell-786f948a67164720",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LdX7yOEI4xLY"
      },
      "outputs": [],
      "source": [
        "class UNetBatchCreator(BatchCreator):\n",
        "\n",
        "    def __init__(self, patch_extractor, dataset, border_pad_size):\n",
        "        super(UNetBatchCreator, self).__init__(patch_extractor, dataset,\n",
        "                                                    border_pad_size)\n",
        "\n",
        "        self.patch_location_sampler = BalancedSampler(self.lbls, self.msks)\n",
        "    \n",
        "    def create_batch(self, batch_size):\n",
        "        '''\n",
        "        returns a batch of image patches (x) with corresponding label patches (y) in one-hot structure\n",
        "        '''\n",
        "        x_data = np.zeros((batch_size, *self.patch_extractor.patch_size, 3))\n",
        "        y_data = np.zeros((batch_size, *self.patch_extractor.patch_size, 2))  # one-hot encoding\n",
        "\n",
        "        locations = self.patch_location_sampler.generate_sample_locations(batch_size)\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        \n",
        "        return x_data, y_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5f91e8207c4391ac78aa9226b49faa4e",
          "grade": true,
          "grade_id": "cell-26c43e442862bdc9",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "airn91W74xLY"
      },
      "outputs": [],
      "source": [
        "'''DO NOT MODIFY THIS CELL'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8695a714751bcf7ad23373987d766821",
          "grade": false,
          "grade_id": "cell-bd04766bce920e37",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tyvfzPcq4xLY"
      },
      "source": [
        "## Implement and train a baseline U-Net model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c2122d908719838f5531a73d3dbb5bfc",
          "grade": false,
          "grade_id": "cell-7d2ef262b397db0d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BpVvv0K14xLY"
      },
      "source": [
        "Here we explicitly define a baseline U-Net model. It has a depth of 4 (3 pooling layers), it uses 'same' convolutions and it starts with 16 filters in the first layer. We will still use patch-based training for U-Net. We have defined the input to the network to be an image patch of size 88x88 (you could also try with other patch sizes). Let's call it ``unet_1``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f696eb4b53504fa24da982595fd85e85",
          "grade": false,
          "grade_id": "cell-71448387401d43ee",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hhc-4dKK4xLY"
      },
      "outputs": [],
      "source": [
        "def build_unet_1(printmodel=True):\n",
        "    \n",
        "    inputs = Input(shape=(None, None, 3))\n",
        "\n",
        "    # First conv pool\n",
        "    c1 = Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(16, 3, activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D()(c1)\n",
        "\n",
        "    # Second conv pool\n",
        "    c2 = Conv2D(32, 3, activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(32, 3, activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D()(c2)\n",
        "\n",
        "    # Third conv pool\n",
        "    c3 = Conv2D(64, 3, activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(64, 3, activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling2D()(c3)\n",
        "\n",
        "    # Fourth conv pool\n",
        "    c4 = Conv2D(128, 3, activation='relu', padding='same')(p3)\n",
        "    c4 = Conv2D(128, 3, activation='relu', padding='same')(c4)\n",
        "\n",
        "    # First up-conv\n",
        "    u2 = UpSampling2D()(c4)\n",
        "    m2 = concatenate([c3, u2])\n",
        "    cm2 = Conv2D(64, 3, activation='relu', padding='same')(m2)\n",
        "    cm2 = Conv2D(64, 3, activation='relu', padding='same')(cm2)\n",
        "\n",
        "    # Third up-conv\n",
        "    u3 = UpSampling2D()(cm2)\n",
        "    m3 = concatenate([c2, u3])\n",
        "    cm3 = Conv2D(32, 3, activation='relu', padding='same')(m3)\n",
        "    cm3 = Conv2D(32, 3, activation='relu', padding='same')(cm3)\n",
        "\n",
        "    # Fourth up-conv\n",
        "    u4 = UpSampling2D()(cm3)\n",
        "    m4 = concatenate([c1, u4])\n",
        "    cm4 = Conv2D(16, 3, activation='relu', padding='same')(m4)\n",
        "    cm4 = Conv2D(16, 3, activation='relu', padding='same')(cm4)\n",
        "\n",
        "    # Output\n",
        "    predictions = Conv2D(2, 1, activation='softmax')(cm4)\n",
        "\n",
        "    model = Model(inputs, predictions)\n",
        "    \n",
        "    if printmodel:\n",
        "        print(model.summary())\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0b7f587308ccbb1ffd10250f2b164f85",
          "grade": false,
          "grade_id": "cell-2a4ed5e3b4c92287",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HUy6ayDd4xLY"
      },
      "source": [
        "Make an instance of the ``unet_1`` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6b88ae7a553a21891baf8ea5aafb2b3d",
          "grade": false,
          "grade_id": "cell-19878dfd31938a3a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UjdriV0J4xLZ"
      },
      "outputs": [],
      "source": [
        "unet_1 = build_unet_1()\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = Adam(learning_rate)\n",
        "\n",
        "unet_1.compile(optimizer, loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e93dde85bd513399bbf0864308273cf8",
          "grade": false,
          "grade_id": "cell-57b3810fd2062582",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "K2fh9sxu4xLZ"
      },
      "source": [
        "Initialize all training parameters, define an image generator that will be able to return mini-batches during the training procedure, define a loss function, the mini-batch size, and other parameters needed to train U-Net. Replace ``None`` with some values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b6b620c18e99e0a55b048465cb57c692",
          "grade": false,
          "grade_id": "cell-5c38c447259cdd80",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tPrsNMsk4xLZ"
      },
      "outputs": [],
      "source": [
        "patch_size = (None, None)\n",
        "batch_size = None\n",
        "steps_per_epoch = 100\n",
        "epochs = None\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ab503ca4c8507c25f6120032e0681b37",
          "grade": true,
          "grade_id": "cell-bdeb8112a2327a7a",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6jmkHSDJ4xLa"
      },
      "outputs": [],
      "source": [
        "'''DO NOT MODIFY THIS CELL'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d3db0fda6daaffa69db2b786ca62d43d",
          "grade": false,
          "grade_id": "cell-05032a44b9217be9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4mve8Q3a4xLa"
      },
      "source": [
        "We also provide you a ``UNetLogger`` class. Note that during validation, we do not pad image borders with half the patch size with 0s as before. Because we use same padding for U-Net, the output should have the same size as the input. But there is an exception where the input size cannot be divisable by the maximum downsampling rate (in our baseline U-Net, it is 8 (three poolings and each of them divides the size by 2)). To force the output and input to have the same size, we pad the input to a shape that is divisable by 8, implemented by the ``pad_ensure_division`` function.  Check the ``validation`` function and compare with the ``Logger`` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "43ddafa23b1dbcc5dc2a3adf90c510db",
          "grade": false,
          "grade_id": "cell-9f2e5cd9a9bd2e0f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tiQ26cHB4xLa"
      },
      "outputs": [],
      "source": [
        "def pad_ensure_division(h, w, division):\n",
        "\n",
        "    def compute_pad(s, d):\n",
        "        if s % d != 0:\n",
        "            p = 0\n",
        "            while True:\n",
        "                if (s + p) % d == 0:\n",
        "                    return p\n",
        "                p += 1\n",
        "        return 0\n",
        "\n",
        "    py = compute_pad(h, division)\n",
        "    px = compute_pad(w, division)\n",
        "    padding = (py//2, py-py//2), (px//2, px-px//2)\n",
        "    return padding\n",
        "\n",
        "\n",
        "class UNetLogger(tensorflow.keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, validation_data):\n",
        "        self.val_imgs = np.asarray(validation_data.imgs) / 255.\n",
        "        self.val_lbls = np.asarray(validation_data.lbls) > 0\n",
        "        self.val_msks = np.asarray(validation_data.msks) > 0\n",
        "\n",
        "        self.losses = []\n",
        "        self.dices = []\n",
        "        self.best_dice = -1\n",
        "        self.best_model = None\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        dice = self.validate()\n",
        "        self.dices.append([len(self.losses), dice])\n",
        "        if dice > self.best_dice:\n",
        "            print('updating the best model')\n",
        "            self.best_dice = dice\n",
        "            self.best_model = self.model.get_weights()\n",
        "        self.plot()\n",
        "\n",
        "    def validate(self):\n",
        "        # need to pad image such that the size can be divisable by 8\n",
        "        h, w = self.val_imgs.shape[1:3]\n",
        "        (py0, py1), (px0, px1) = pad_ensure_division(h, w, 8)\n",
        "        padding = ((0, 0), (py0, py1), (px0, px1), (0, 0))\n",
        "        pad_val_imgs = np.pad(self.val_imgs, pad_width=padding, mode='constant')\n",
        "\n",
        "        # run unet model\n",
        "        predicted_lbls = np.argmax(self.model.predict(pad_val_imgs, batch_size=1), axis=-1)\n",
        "        \n",
        "        # crop it back because we pad it before\n",
        "        b, h, w = predicted_lbls.shape\n",
        "        predicted_lbls = predicted_lbls[:, py0:h-py1, px0:w-px1]\n",
        "\n",
        "        x = self.val_lbls[self.val_msks]\n",
        "        y = predicted_lbls[self.val_msks]\n",
        "        \n",
        "        return calculate_dice(x, y)\n",
        "\n",
        "    def plot(self):\n",
        "        clear_output()\n",
        "        N = len(self.losses)\n",
        "        train_loss_plt, = plt.plot(range(0, N), self.losses)\n",
        "        dice_plt, = plt.plot(*np.array(self.dices).T)\n",
        "        plt.legend((train_loss_plt, dice_plt),\n",
        "                   ('training loss', 'validation dice'))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1632d18c5556ca9f1d60402b74d3c7a1",
          "grade": false,
          "grade_id": "cell-c7f0c591eede05fc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Eg6Wr0CW4xLa"
      },
      "outputs": [],
      "source": [
        "patch_extractor = PatchExtractor(patch_size, horizontal_flipping=True)\n",
        "batch_creator = UNetBatchCreator(patch_extractor, train_data, patch_size)\n",
        "patch_generator = batch_creator.get_generator(batch_size)\n",
        "\n",
        "logger_3 = UNetLogger(validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "621861fb46e079bd5b31e3b79b40f096",
          "grade": false,
          "grade_id": "cell-9d1a436b98bdbeb9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zvpvj1DH4xLb"
      },
      "source": [
        "Now we train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "83bc14e9e3060d0e676423257ec0cd22",
          "grade": false,
          "grade_id": "cell-f3f17c5bdaac376c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YPXJKbho4xLb"
      },
      "outputs": [],
      "source": [
        "if overwrite or not Path('./unet_1').exists():\n",
        "    unet_1.fit_generator(generator=patch_generator,\n",
        "                      steps_per_epoch=steps_per_epoch,\n",
        "                      epochs=epochs, callbacks=[logger_3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0c2ad7d33169620d668f3b5468782d53",
          "grade": false,
          "grade_id": "cell-403fde6f81df9d07",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "LMeBaphb4xLb"
      },
      "source": [
        "We also need to change the ``process_basic`` function a bit in order to process one image using U-Net. Remember you need to pad the image when its size cannot be divided by the total downsampling rate in your U-Net (in our baseline U-Net it is 8). This ensures that the output size and the input size of the U-Net model are always the same. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5a4c04cfbdb0e1e8e359ef49c1945f04",
          "grade": false,
          "grade_id": "cell-e4870578712a593e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mXZ67yU64xLb"
      },
      "outputs": [],
      "source": [
        "def process_unet(model, imgs):\n",
        "    # pad image if the size is not divisable by total downsampling rate in your U-Net \n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    # run unet model\n",
        "    output = model.predict(pad_imgs, batch_size=1)[:, :, :, 1]\n",
        "    \n",
        "    # don't forget to crop it back because you pad it before.\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    return lbls, msks, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4fc130a3c8e60d9c9e018ddd17c8e6a7",
          "grade": true,
          "grade_id": "cell-48dca83a84171144",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KZU_HCUu4xLb"
      },
      "outputs": [],
      "source": [
        "\"\"\" DO NOT MODIFY THIS CELL\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "38a6586286de56c5079332f3be5e8569",
          "grade": false,
          "grade_id": "cell-ca9dace6bfd806de",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "jAqxCbwh4xLb"
      },
      "source": [
        "Now we run the best model on the validation images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAwIFCoU4xLb"
      },
      "outputs": [],
      "source": [
        "def check_results_unet(imgs, lbls, msks, output, threshold=0.5):\n",
        "\n",
        "    dices = []\n",
        "    for i, (img, lbl, msk, raw_output) in enumerate(zip(imgs, lbls, msks, output)):\n",
        "        final_output = raw_output > threshold\n",
        "        \n",
        "#         print('Output_mask: {}\\nLbl: {}'.format(final_output[3].shape, lbl.shape))\n",
        "        dice = calculate_dice(final_output[i], lbls[i])\n",
        "        dices.append(dice)\n",
        "        print('image:', i, 'dice', dice)\n",
        "        \n",
        "        # plot the results\n",
        "        matplotlib.rcParams['figure.figsize'] = (15, 6)\n",
        "        f, axes = plt.subplots(1, 4)\n",
        "        for ax, im, t in zip(axes, \n",
        "                             (img, raw_output[i], final_output[i], lbl), \n",
        "                             ('RGB image', 'Soft prediction', 'Thresholded', 'Ground truth')):\n",
        "            ax.imshow(im, cmap='gray')\n",
        "            ax.set_title(t)\n",
        "        plt.show()\n",
        "        \n",
        "    print('mean dice', np.mean(dices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5289fe2d75c3104ad8ef1c21ec64fad0",
          "grade": false,
          "grade_id": "cell-0f3e496823f05193",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LpCCX5Z14xLb"
      },
      "outputs": [],
      "source": [
        "if overwrite or not Path('./unet_1').exists():\n",
        "    unet_1.set_weights(logger_3.best_model)\n",
        "    unet_1.save('./unet_1')\n",
        "else:\n",
        "    print('loading saved unet_1')\n",
        "    unet_1 = load_model('./unet_1')\n",
        "    \n",
        "imgs = np.asarray(validation_data.imgs) / 255.\n",
        "lbls = np.asarray(validation_data.lbls) > 0\n",
        "msks = np.asarray(validation_data.msks) > 0\n",
        "output = process_unet(unet_1, imgs)\n",
        "# print((validation_data.lbls[3].shape))\n",
        "\n",
        "check_results_unet(validation_data.imgs, lbls, msks, output, threshold=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7993b8f2e9d22bd17d4bb5535943581d",
          "grade": false,
          "grade_id": "cell-306e80cdebc21283",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XWpx5k524xLb"
      },
      "source": [
        "## Improve the U-Net implementation to increase performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3aeb9a5da5d31f2d774275f9f48bf766",
          "grade": false,
          "grade_id": "cell-04bdf61564c717cc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xhP-sfPS4xLc"
      },
      "source": [
        "You have realized that this baseline model does not perform well. Now, it is time to boost performance. These are different ideas:\n",
        "- You can adjust the different training hyperparameters (learning rate, mini-batch size, etc.).\n",
        "- You can change the number of filters per layer by passing a different input parameter ``initial_filters`` (default = 16) to ``build_unet_2()``, and experiment the effect of using a wider U-Net model.\n",
        "- You can make use of different techniques seen during the lessons (batch normalization, dropout, etc).\n",
        "- You can add class weights in your loss function for balancing positive and negative classses (last optional task).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "826d2c25e4381071500d232af6eb392d",
          "grade": false,
          "grade_id": "cell-065855b0df4cb1d4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XJg27GHW4xLc"
      },
      "source": [
        "Additionally, a U-Net model can be built by writing a simple program, because U-Net blocks have all the same structure, which can be coded as a function. Here we implement U-Net blocks, which will make the design of more U-Net architectures in this assignment much easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "02a6bac40aaf846634e8c59b99b7dd1c",
          "grade": false,
          "grade_id": "cell-d7a4375282bc447f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PqNo8iMF4xLc"
      },
      "outputs": [],
      "source": [
        "# Create a function that builds a U-Net block, containing conv->(batchnorm->dropout->)conv->(batchnorm->dropout),\n",
        "# where batchnorm and dropout are optional and can be selected via input parameters.\n",
        "# The function returns the output of the block layers.\n",
        "def unet_block(inputs, n_filters, batchnorm=False, dropout=False):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    return cl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d65f0c0ab8ed4b3abddff938fa44426e",
          "grade": true,
          "grade_id": "cell-241e4ba095c90b2b",
          "locked": true,
          "points": 15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2xJ145WI4xLc"
      },
      "outputs": [],
      "source": [
        "\"\"\" DO NOT MODIFY THIS CELL \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "50aa2b4ab3520b2cc141756cf9e68102",
          "grade": false,
          "grade_id": "cell-f1520680fa505b02",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CF_6SM034xLc"
      },
      "source": [
        "Use ``unet_block()`` to build a U-Net model with a script: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "83fa20f54021d730abe752609a70e3b9",
          "grade": false,
          "grade_id": "cell-4406284dda4fa122",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "E8QFKub94xLc"
      },
      "outputs": [],
      "source": [
        "def build_unet_2(initial_filters=16, n_classes=2, batchnorm=False, dropout=False, printmodel=False):\n",
        "\n",
        "    # build U-Net again using unet_block function\n",
        "    inputs = Input(shape=(None, None, 3)) #adjust\n",
        "\n",
        "    # CONTRACTION PART\n",
        "\n",
        "    # First conv pool\n",
        "    c1 = unet_block(inputs, initial_filters, batchnorm, dropout)\n",
        "    p1 = MaxPooling2D()(c1)\n",
        "\n",
        "    # Second conv pool\n",
        "    c2 = unet_block(p1, 2*initial_filters, batchnorm, dropout)\n",
        "    p2 = MaxPooling2D()(c2)\n",
        "\n",
        "    # Third conv pool\n",
        "    c3 = unet_block(p2, 4*initial_filters, batchnorm, dropout)\n",
        "    p3 = MaxPooling2D()(c3)\n",
        "\n",
        "    # Fourth conv\n",
        "    c4 = unet_block(p3, 8*initial_filters, batchnorm, dropout)\n",
        "\n",
        "    # EXPANSION PART\n",
        "\n",
        "    # First up-conv\n",
        "    u2 = UpSampling2D()(c4)\n",
        "    m2 = concatenate([c3, u2])\n",
        "    cm2 = unet_block(m2, 4*initial_filters, batchnorm, dropout)\n",
        "\n",
        "    # Second up-conv\n",
        "    u3 = UpSampling2D()(cm2)\n",
        "    m3 = concatenate([c2, u3])\n",
        "    cm3 = unet_block(m3, 2*initial_filters, batchnorm, dropout)\n",
        "\n",
        "    # Third up-conv\n",
        "    u4 = UpSampling2D()(cm3)\n",
        "    m4 = concatenate([c1, u4])\n",
        "    cm4 = unet_block(m4, initial_filters, batchnorm, dropout)\n",
        "\n",
        "    # Output\n",
        "    predictions = Conv2D(n_classes, 1, activation='softmax')(cm4)\n",
        "\n",
        "    model = Model(inputs, predictions)\n",
        "    \n",
        "    if printmodel:\n",
        "        print(model.summary())\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhXxBe-14xLc"
      },
      "source": [
        "Make an instance of the ``unet_2`` model and initialize all required training parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6872519e8f8613d3f5c667cfb51f9369",
          "grade": false,
          "grade_id": "cell-1b5fb69ea7e815f2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bBvTYsRq4xLc"
      },
      "outputs": [],
      "source": [
        "learning_rate = None      #Set a learning rate\n",
        "patch_size = None\n",
        "batch_size = None\n",
        "steps_per_epoch = None\n",
        "epochs = None\n",
        "\n",
        "\n",
        "unet_2 = build_unet_2(initial_filters=16, n_classes=2, batchnorm=True, dropout=True, printmodel=True)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "optimizer = Adam(learning_rate)\n",
        "unet_2.compile(optimizer, loss='categorical_crossentropy')\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "patch_extractor = PatchExtractor(patch_size, horizontal_flipping=True)\n",
        "batch_creator = UNetBatchCreator(patch_extractor, train_data, patch_size)\n",
        "patch_generator = batch_creator.get_generator(batch_size)\n",
        "logger_4 = UNetLogger(validation_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5bd826efbad1c90974739b039cfe747d",
          "grade": true,
          "grade_id": "cell-0adf114b922a0c2f",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dyAeOLfY4xLc"
      },
      "outputs": [],
      "source": [
        "'''DO NOT MODIFY THIS CELL'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cac2e6cdd021152fc57885eb4d163dce",
          "grade": false,
          "grade_id": "cell-deb10375d0ee41ed",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tPDdGIwp4xLd"
      },
      "source": [
        "Train your new U-Net model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3xuIofgN4xLd"
      },
      "outputs": [],
      "source": [
        "if overwrite or not Path('./unet_2').exists():\n",
        "    unet_2.fit_generator(generator=patch_generator,\n",
        "                      steps_per_epoch=steps_per_epoch,\n",
        "                      epochs=epochs, callbacks=[logger_4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0a76e736b7079f8d462288178d98fdf9",
          "grade": false,
          "grade_id": "cell-b703cdd2eef8307b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4qEDV0_v4xLd"
      },
      "source": [
        "Run the best  model on the validation images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yOG8shR_4xLd"
      },
      "outputs": [],
      "source": [
        "if overwrite or not Path('./unet_2').exists():\n",
        "    unet_2.set_weights(logger_4.best_model)\n",
        "    unet_2.save('./unet_2')\n",
        "else:\n",
        "    unet_2 = load_model('./unet_2')\n",
        "imgs = np.asarray(validation_data.imgs) / 255.\n",
        "lbls = np.asarray(validation_data.lbls) > 0\n",
        "msks = np.asarray(validation_data.msks) > 0\n",
        "output = process_unet(unet_2, imgs)\n",
        "check_results_unet(validation_data.imgs, lbls, msks, output, threshold=0.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "068b693c97ab3742050968d458b2d6a3",
          "grade": false,
          "grade_id": "cell-762e335752fa26c2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-nrVZqdv4xLd"
      },
      "source": [
        "## Submit test results to grand-challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1099847a33056e9c4167ce0d43d3fb80",
          "grade": false,
          "grade_id": "cell-6582d9ad2ee67f70",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-QJ5SkM-4xLd"
      },
      "source": [
        "Now you can process images in the test set and submit your results to grand-challenge.\n",
        "You can tune the threshold and (optionally) apply the mask before submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7793c0ebfab0d77956b70cf9ec786033",
          "grade": false,
          "grade_id": "cell-bb5c9d2005633e20",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dYvbx1Hv4xLd"
      },
      "outputs": [],
      "source": [
        "# define output folder\n",
        "result_output_folder = './results2'\n",
        "if not os.path.exists(result_output_folder):\n",
        "    os.makedirs(result_output_folder)\n",
        "\n",
        "# threshold to select segmented pixels\n",
        "threshold = 0.5\n",
        "\n",
        "# pad all images in the test set\n",
        "imgs = np.asarray(test_imgs) / 255.\n",
        "output = process_unet(unet_2, imgs)\n",
        "# save all output masks as png images\n",
        "for i in range(len(output[0])):\n",
        "\n",
        "    # output has to be:\n",
        "    # - thresholded\n",
        "    # - converted to grayscale\n",
        "    print(output[0].shape)\n",
        "    img = output[0]\n",
        "    segmentation = 255 * (img[i, :, :].squeeze() > threshold).astype(int)\n",
        "    \n",
        "    # save to disk\n",
        "    im = Image.fromarray(segmentation.astype('uint8'))\n",
        "    im.save(os.path.join(result_output_folder, \"{}.png\".format(i + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "de2155cfcdbb56a51918e79eadc9cb05",
          "grade": false,
          "grade_id": "cell-a0cf96ac9668ec80",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lQL-n91M4xLd"
      },
      "outputs": [],
      "source": [
        "shutil.make_archive('results2', 'zip', result_output_folder)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "iM2W2IKdPYN1",
        "SQJ8WyczPYO1",
        "tHKcU79bPYPA"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "name": "tf2-gpu.2-4.mnightly-2021-01-20-debian-10-test",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:mnightly-2021-01-20-debian-10-test"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}